# ==============================================================================
# Full R Code: CNN-LSTM with All Copula NLL Losses (Final Corrected Version)
# - tfprobability removed
# - tf$math$erf_inv changed to tf$math$erfinv
# - Conv1D padding="same" added for Timestep=1 data (CGD fix)
# ==============================================================================

# 0️⃣ Library Setup
# ==============================================================================
library(keras)
library(keras3)
library(tensorflow)
library(dplyr)
library(tidyr)
library(ggplot2)
library(copula)
library(gridExtra)
library(kableExtra)
library(viridis)
library(JM) # For pbc2.id and cgd datasets
set.seed(123)

# ==============================================================================
# Utility Functions
# ==============================================================================

# Uniform transform (sigmoid + clipping)
to_uniform_tf <- function(x) {
  u <- tf$math$sigmoid(tf$cast(x, tf$float32))
  tf$clip_by_value(u, 1e-6, 1 - 1e-6)
}

# Gaussian CDF to Z-space (CRITICAL FIX: using tf$math$erfinv)
u_to_z <- function(u) {
  u_clipped <- tf$clip_by_value(u, 1e-6, 1 - 1e-6)
  tf$math$sqrt(2.0) * tf$math$erfinv(2.0 * u_clipped - 1.0)
}

# Gaussian Copula Density (Log, 3D)
log_gaussian_copula_density <- function(u, R) {
  z <- u_to_z(u)
  eps <- 1e-6
  invR <- tf$linalg$inv(R + eps * tf$eye(3L))
  diff_mat <- invR - tf$eye(3L)
  z_col <- tf$reshape(z, tf$stack(list(tf$shape(z)[1], tf$shape(z)[2], 1L)))
  quad <- tf$matmul(tf$matmul(tf$transpose(z_col, perm = c(0L, 2L, 1L)), diff_mat), z_col)
  quad_term <- tf$reshape(quad, tf$stack(list(tf$shape(z)[1])))
  detR <- tf$linalg$det(R + eps * tf$eye(3L))
  -0.5 * quad_term - 0.5 * tf$math$log(detR + eps)
}


# ==============================================================================
# Copula Loss Functions (3D)
# ==============================================================================

# 1️⃣ Gaussian Copula NLL (TF-Native 3D)
copula_gaussian_loss <- function(y_true, y_pred) {
  y_pred <- tf$cast(y_pred, tf$float32)
  R_matrix <- tf$constant(diag(3) + 1e-6, dtype = tf$float32) 
  R <- tf$cast(R_matrix, tf$float32)
  u_pred <- to_uniform_tf(y_pred)
  log_c_density <- log_gaussian_copula_density(u_pred, R)
  nll <- -log_c_density
  tf$reduce_mean(nll)
}

# 2️⃣ Clayton Copula NLL Loss (3D)
copula_clayton_loss <- function(y_true, y_pred, theta_init = 1.5) {
  y_pred <- tf$cast(y_pred, tf$float32)
  theta <- tf$maximum(tf$cast(theta_init, tf$float32), 0.01)

  u_pred <- to_uniform_tf(y_pred)
  S <- tf$reduce_sum(tf$math$pow(u_pred, -theta), axis = 1L)

  log_term_const <- tf$math$log(1 + theta) + tf$math$log(1 + 2 * theta)
  log_term_prod <- - (theta + 1) * tf$reduce_sum(tf$math$log(u_pred), axis = 1L)
  log_term_power <- - (3 + 1 / theta) * tf$math$log(S - 2 + 1e-6)

  log_C_density <- log_term_const + log_term_prod + log_term_power
  nll <- -log_C_density
  tf$reduce_mean(nll)
}

# 3️⃣ Gumbel Copula NLL Loss (3D)
copula_gumbel_loss <- function(y_true, y_pred, theta_init = 2.0) {
  y_pred <- tf$cast(y_pred, tf$float32)
  theta <- tf$maximum(tf$cast(theta_init, tf$float32), 1.001)
  u_pred <- to_uniform_tf(y_pred)
  
  log_u <- -tf$math$log(u_pred)
  phi_u <- tf$math$pow(log_u, theta)
  sum_phi_u <- tf$reduce_sum(phi_u, axis = 1L)
  
  term1 <- -tf$math$pow(sum_phi_u, 1 / theta)
  term2 <- (1 / theta - 3) * tf$math$log(sum_phi_u + 1e-6)
  term3 <- tf$reduce_sum((theta - 1) * tf$math$log(log_u + 1e-6) - tf$math$log(u_pred + 1e-6), axis = 1L)
  
  inner_sum1 <- tf$math$pow(sum_phi_u, 2 / theta)
  inner_sum2 <- 3 * (theta - 1) * tf$math$pow(sum_phi_u, 1 / theta)
  inner_sum3 <- (2 * theta^2 - 3 * theta + 1)
  term4 <- tf$math$log(inner_sum1 + inner_sum2 + inner_sum3 + 1e-6)
  
  log_c_density <- term1 + term2 + term3 + term4
  nll <- -log_c_density
  tf$reduce_mean(nll)
}

# 4️⃣ Hybrid Clayton–Gumbel Loss (3D)
copula_hybrid_loss <- function(y_true, y_pred,
                               theta_clayton = 1.2,
                               theta_gumbel = 2.0,
                               alpha = 0.5) {
  loss_c <- copula_clayton_loss(y_true, y_pred, theta_clayton)
  loss_g <- copula_gumbel_loss(y_true, y_pred, theta_gumbel)
  tf$reduce_mean(alpha * loss_c + (1 - alpha) * loss_g)
}

# --- Custom Keras Layers (Placeholders) ---
LearnableClaytonActivation <- new_layer_class(
  classname="LearnableClaytonActivation",
  initialize=function(self, theta_init=1.0) { super$initialize(); self$theta <- self$add_weight(shape=list(), initializer=initializer_constant(theta_init), trainable=TRUE, name="theta") },
  call=function(self, inputs) { tf$identity(inputs) }
)
LearnableGumbelActivation <- new_layer_class(
  classname="LearnableGumbelActivation",
  initialize=function(self, theta_init=2.0) { super$initialize(); self$theta <- self$add_weight(shape=list(), initializer=initializer_constant(theta_init), trainable=TRUE, name="theta") },
  call=function(self, inputs) { tf$identity(inputs) }
)
LearnableClaytonGumbelHybrid <- new_layer_class(
  classname="LearnableClaytonGumbelHybrid",
  initialize=function(self, theta_c_init=1.0, theta_g_init=2.0, alpha_init=0.5) {
    super$initialize(); self$theta_c <- self$add_weight(shape=list(), initializer=initializer_constant(theta_c_init), trainable=TRUE, name="theta_c")
    self$theta_g <- self$add_weight(shape=list(), initializer=initializer_constant(theta_g_init), trainable=TRUE, name="theta_g")
    self$alpha <- self$add_weight(shape=list(), initializer=initializer_constant(alpha_init), trainable=TRUE, name="alpha")
  },
  call=function(self, inputs) { tf$identity(inputs) }
)


# ==============================================================================
# CNN-LSTM Model Builder & Trainer
# ==============================================================================

create_cnn_lstm <- function(type = c("clayton", "gumbel", "hybrid"), input_features) {
  type <- match.arg(type)
  
  # Determine current timesteps dynamically for Conv1D/Pooling logic
  # Checks the environment where 'train_and_evaluate' is called (or its caller)
  current_timesteps <- if(exists("timesteps_cgd", envir = parent.frame(2))) {
    get("timesteps_cgd", envir = parent.frame(2))
  } else if (exists("timesteps", envir = parent.frame(2))) {
    get("timesteps", envir = parent.frame(2))
  } else {
    10 # Default fallback
  }

  model <- keras_model_sequential() %>%
    layer_conv_1d(
      filters = 32, 
      kernel_size = 3, 
      activation = "relu",
      # CRITICAL FIX for Timestep=1: Use padding="same"
      padding = "same", 
      input_shape = c(current_timesteps, input_features)
    )
  
  # Conditional Max Pooling: Skip if timesteps=1
  if (current_timesteps > 1) {
    model <- model %>% layer_max_pooling_1d(pool_size = 2)
  }
  
  model <- model %>%
    layer_lstm(units = 64, return_sequences = FALSE) %>%
    layer_dropout(0.3)

  if (type == "clayton") model <- model %>% LearnableClaytonActivation()
  if (type == "gumbel") model <- model %>% LearnableGumbelActivation()
  if (type == "hybrid") model <- model %>% LearnableClaytonGumbelHybrid()

  model %>% layer_dense(units = 3, activation = "linear") # Output 3 N(0,1) variables
}

train_and_evaluate <- function(x_scaled, y_numeric, timesteps, features, model_types, model_names, loss_types) {
  all_results <- list(); all_residuals <- list()

  for (i in seq_along(model_types)) {
    for (loss in loss_types) {
      k_clear_session()
      cat("Training", model_names[i], "with", loss, "loss\n")
      # NOTE: timesteps and features are passed but model finds them in the parent env
      m <- create_cnn_lstm(model_types[i], input_features = dim(x_scaled)[3])

      current_loss_fn <- switch(
        loss,
        "copula_gaussian_loss" = copula_gaussian_loss,
        "copula_clayton_loss" = copula_clayton_loss,
        "copula_gumbel_loss" = copula_gumbel_loss,
        "copula_hybrid_loss" = copula_hybrid_loss
      )
      
      if(is.null(current_loss_fn)) { next }

      m %>% compile(optimizer = "adam", loss = current_loss_fn, metrics = "mae")

      m %>% fit(x_scaled, y_numeric, epochs = 10, batch_size = 32, verbose = 0, validation_split = 0.2)

      preds <- m %>% predict(x_scaled)
      residuals <- y_numeric - preds
      if(ncol(residuals) < 3) residuals <- cbind(residuals, NA) 

      res_df <- data.frame(Model = model_names[i], Loss = loss, ResidualY1 = residuals[,1], ResidualY2 = residuals[,2], ResidualS = residuals[,3])
      all_residuals[[paste0(model_names[i], "_", loss)]] <- res_df

      all_results[[paste0(model_names[i], "_", loss)]] <- data.frame(
        Model = model_names[i], Loss = loss, MeanResidual1 = mean(residuals[,1]), SDResidual1 = sd(residuals[,1]),
        MeanResidual2 = mean(residuals[,2]), SDResidual2 = sd(residuals[,2]),
        MeanResidualS = mean(residuals[,3]), SDResidualS = sd(residuals[,3])
      )
    }
  }
  return(list(results = do.call(rbind, all_results), residuals = do.call(rbind, all_residuals)))
}


# ==============================================================================
# PART 1: SIMULATION STUDY (3-Outcome)
# ==============================================================================

cat("================================\n")
cat("SIMULATION STUDY\n")
cat("================================\n")

n <- 500; timesteps <- 10; features <- 30
x_data_array <- array(runif(n*timesteps*features), dim=c(n,timesteps,features))
x_scaled <- (x_data_array - mean(x_data_array)) / sd(x_data_array)

# Simulate Y1, Y2, and survival S (Latent variables)
beta_Y1 <- rnorm(features); beta_Y2 <- rnorm(features)
rbf_kernel <- function(x_mat) apply(x_mat,1,mean)
x_data_matrix <- apply(x_data_array, c(1,3), mean)
Y1 <- as.numeric(x_data_matrix %*% beta_Y1 + 2*rbf_kernel(x_data_matrix) + rnorm(n,0,0.1))
Y2 <- as.numeric(x_data_matrix %*% beta_Y2 + 1.5*rbf_kernel(x_data_matrix) + rnorm(n,0,0.1))
S_latent <- -log(runif(n)) / (exp(Y1 + Y2)) # S_latent is the third outcome

# For the model, we use the continuous variables directly transformed to N(0,1)
y_numeric <- as.matrix(sapply(data.frame(Y1, Y2, S=S_latent), function(x) qnorm(rank(x)/(length(x)+1))))

# Train simulation models
model_types <- c("clayton", "gumbel", "hybrid")
model_names <- c("Clayton", "Gumbel", "Clayton-Gumbel")
loss_types <- c("copula_gaussian_loss", "copula_clayton_loss", "copula_gumbel_loss", "copula_hybrid_loss")
sim_results <- train_and_evaluate(x_scaled, y_numeric, timesteps, features, model_types, model_names, loss_types)

cat("\nSimulation Residual Summary:\n")
print(kable(sim_results$results, digits = 3, caption = "Simulation Residual Summary") %>% kable_styling(full_width = FALSE))

# ==============================================================================
# PART 2: PBC DATA (3-Outcome)
# ==============================================================================

cat("\n\n================================\n")
cat("REAL DATA: PBC Study\n")
cat("================================\n")

data("pbc2.id", package="JM"); pbc <- pbc2.id
pbc$serBilir <- as.numeric(pbc$serBilir); pbc$albumin <- as.numeric(pbc$albumin); pbc$years <- as.numeric(pbc$years); pbc$status <- as.numeric(pbc$status)

surv_summary <- pbc %>% group_by(id) %>% summarise(surv_time=max(years,na.rm=TRUE), event=as.integer(any(status %in% c(1,2)))) %>% ungroup()
subject_ids <- head(surv_summary$id, 500); pbc <- pbc %>% filter(id %in% subject_ids)
timesteps <- 10; numeric_features <- head(setdiff(names(pbc), c("id","years","status","drug","sex","ascites","hepatomegaly","spiders","edema","histol")), 30)
long_data <- pbc[, c("id","years",numeric_features)]; long_data <- long_data[order(long_data$id,long_data$years),]

# Prepare X-array
subject_list <- split(long_data, long_data$id)
pad_subject <- function(df, features, tsteps) {
  mat <- as.matrix(df[, features, drop=FALSE])
  if(nrow(mat) >= tsteps) mat[1:tsteps,] else rbind(mat, matrix(0, nrow=tsteps-nrow(mat), ncol=ncol(mat)))
}
x_array <- array(unlist(lapply(subject_list, pad_subject, numeric_features, timesteps)), dim=c(length(subject_list),timesteps,length(numeric_features)))
for(j in 1:dim(x_array)[3]){ col_data <- x_array[,,j]; col_data[is.na(col_data)] <- mean(col_data[col_data!=0], na.rm=TRUE); x_array[,,j] <- col_data }
x_scaled <- (x_array - mean(x_array, na.rm=TRUE)) / sd(x_array, na.rm=TRUE)
x_scaled[is.na(x_scaled)] <- 0

# Prepare Y (Last serBilir, Last albumin, Survival Time)
y_data_df <- surv_summary %>% left_join(long_data %>% group_by(id) %>% summarise(Y_serBilir=last(serBilir), Y_albumin=last(albumin)), by="id") %>% dplyr::select(Y_serBilir,Y_albumin,S=surv_time) %>% na.omit()
y_numeric <- as.matrix(sapply(y_data_df, function(x) qnorm(rank(x)/(length(x)+1))))
x_scaled <- x_scaled[1:nrow(y_numeric), , ] # Align X and Y

# Train PBC models
real_results <- train_and_evaluate(x_scaled, y_numeric, timesteps, length(numeric_features), model_types, model_names, loss_types)

cat("\nReal PBC Residual Summary:\n")
print(kable(real_results$results, digits = 3, caption = "Real PBC Residual Summary") %>% kable_styling(full_width = FALSE))


# ==============================================================================
# PART 3: CGD DATA (3-Outcome, Timesteps=1)
# ==============================================================================

cat("\n\n================================\n")
cat("REAL DATA: CGD Study\n")
cat("================================\n")

data("cgd"); time <- cgd$tstop - cgd$tstart; event <- cgd$status
X <- model.matrix(~0+treat+sex, data=cgd)
x_array <- array(as.matrix(X), dim=c(nrow(X),1,ncol(X))) # Timesteps = 1
x_scaled <- (x_array - mean(x_array)) / sd(x_array)
y_numeric <- as.matrix(sapply(data.frame(Y1=time,Y2=event,S=time), function(x) qnorm(rank(x)/(length(x)+1))))

# Train CGD models (Uses timesteps_cgd=1 for the model builder)
timesteps_cgd <- 1 
features_cgd <- ncol(X)

# The train_and_evaluate function now correctly handles timesteps=1 via the create_cnn_lstm function
cgd_results <- train_and_evaluate(x_scaled, y_numeric, timesteps_cgd, features_cgd, model_types, model_names, loss_types)

cat("\nReal CGD Residual Summary:\n")
print(kable(cgd_results$results, digits = 3, caption = "Real CGD Residual Summary") %>% kable_styling(full_width = FALSE))

# ==============================================================================
# Final Combined Summary
# ==============================================================================
all_results_combined <- bind_rows(
    sim_results$results %>% mutate(Dataset = "Simulated"),
    real_results$results %>% mutate(Dataset = "PBC"),
    cgd_results$results %>% mutate(Dataset = "CGD")
)

cat("\n\n================================\n")
cat("COMBINED RESULTS SUMMARY (Mean/SD of Residuals)\n")
cat("================================\n")
print(kable(all_results_combined, digits = 3, caption = "Combined Residual Summaries (Mean/SD)") %>%
          kable_styling(full_width = FALSE) %>%
          group_rows("Simulated", 1, nrow(sim_results$results)) %>%
          group_rows("PBC", nrow(sim_results$results) + 1, nrow(sim_results$results) + nrow(real_results$results)) %>%
          group_rows("CGD", nrow(sim_results$results) + nrow(real_results$results) + 1, nrow(all_results_combined))
)

# ==============================================================================
# PART 4: RESIDUAL ANALYSIS AND PLOTTING
# ==============================================================================

library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(kableExtra)

cat("\n\n================================\n")
cat("RESIDUAL ANALYSIS AND PLOTTING\n")
cat("================================\n")

# 1️⃣ Transform Residuals into Long Format

# Simulation Residuals
sim_residuals_long <- sim_results$residuals %>%
  tidyr::pivot_longer(
    cols = c(ResidualY1, ResidualY2, ResidualS), names_to = "Outcome", values_to = "Residual") %>%
  mutate(Outcome = gsub("Residual", "", Outcome), Dataset = "Simulated")

# PBC Residuals
real_residuals_long <- real_results$residuals %>%
  tidyr::pivot_longer(
    cols = c(ResidualY1, ResidualY2, ResidualS), names_to = "Outcome", values_to = "Residual") %>%
  mutate(Outcome = gsub("ResidualY1", "serBilir", Outcome),
         Outcome = gsub("ResidualY2", "albumin", Outcome),
         Outcome = gsub("ResidualS", "Survival", Outcome),
         Dataset = "PBC")

# CGD Residuals
cgd_residuals_long <- cgd_results$residuals %>%
    pivot_longer(
        cols = c(ResidualY1, ResidualY2, ResidualS),
        names_to = "Outcome",
        values_to = "Residual"
    ) %>%
    mutate(
        Outcome = gsub("ResidualY1", "Time", Outcome),
        Outcome = gsub("ResidualY2", "Event", Outcome),
        Outcome = gsub("ResidualS", "Survival", Outcome),
        Dataset = "CGD"
    )

# 2️⃣ Combine all residual data
combined_residuals_long <- bind_rows(
    sim_residuals_long,
    real_residuals_long,
    cgd_residuals_long
)

# 3️⃣ Density Plot: Residuals by Model and Outcome
p_combined_density <- ggplot(combined_residuals_long, aes(x = Residual, fill = Loss)) +
    geom_density(alpha = 0.55, adjust = 1.2) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
    facet_grid(Dataset + Model ~ Outcome, scales = "free") +
    theme_minimal(base_size = 10) +
    scale_fill_viridis_d(option = "C", end = 0.8) +
    labs(
        title = "Residual Density Comparison Across Datasets (Sim, PBC, CGD)",
        subtitle = "A good model should produce residuals centered around zero (N(0,1) scale)",
        x = "Residual (Standard Normal Scale)", y = "Density", fill = "Loss Function"
    ) +
    theme(
        plot.title = element_text(face = "bold", size = 12),
        legend.position = "bottom",
        strip.text = element_text(size = 9)
    )

print(p_combined_density)
# 

---

# 4️⃣ Boxplot: Residual spread comparison
p_combined_box <- ggplot(combined_residuals_long, aes(x = Loss, y = Residual, fill = Loss)) +
    geom_boxplot(alpha = 0.6, outlier.size = 0.5, width = 0.6) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
    facet_grid(Dataset + Model ~ Outcome, scales = "free_y") +
    theme_minimal(base_size = 10) +
    scale_fill_viridis_d(option = "C", end = 0.8) +
    labs(
        title = "Residual Spread Across Datasets (Sim, PBC, CGD)",
        subtitle = "Closer median to zero and tighter IQR indicates better fit",
        x = "Loss Function", y = "Residual (Standard Normal Scale)"
    ) +
    theme(
        plot.title = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
        strip.text = element_text(size = 9, face = "bold"),
        legend.position = "none"
    )

print(p_combined_box)
# 


# 5️⃣ Final Combined Summary Table
all_results_combined <- bind_rows(
    sim_results$results %>% mutate(Dataset = "Simulated"),
    real_results$results %>% mutate(Dataset = "PBC"),
    cgd_results$results %>% mutate(Dataset = "CGD")
)

cat("\n\n================================\n")
cat("COMBINED RESULTS SUMMARY (Mean/SD of Residuals)\n")
cat("================================\n")
print(kable(all_results_combined, digits = 3, caption = "Combined Residual Summaries (Mean/SD)") %>%
          kable_styling(full_width = FALSE) %>%
          group_rows("Simulated", 1, nrow(sim_results$results)) %>%
          group_rows("PBC", nrow(sim_results$results) + 1, nrow(sim_results$results) + nrow(real_results$results)) %>%
          group_rows("CGD", nrow(sim_results$results) + nrow(real_results$results) + 1, nrow(all_results_combined))
)

library(ggplot2)
library(dplyr)
library(viridis)

p_sim_density <- combined_residuals_long %>%
    filter(Dataset == "Simulated") %>%
    ggplot(aes(x = Residual, fill = Loss)) +
    geom_density(alpha = 0.55, adjust = 1.5) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
    facet_grid(Model ~ Outcome, scales = "free_y") +
    theme_minimal(base_size = 12) +
    scale_fill_viridis_d(option = "C", end = 0.8) +
    labs(
        title = "Residual Density for Simulated Data",
        subtitle = "Y1, Y2, and Survival Outcomes (N(0,1) Scale)",
        x = "Residual", y = "Density", fill = "Loss Function"
    ) +
    theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_sim_density)


p_pbc_density <- combined_residuals_long %>%
    filter(Dataset == "PBC") %>%
    ggplot(aes(x = Residual, fill = Loss)) +
    geom_density(alpha = 0.55, adjust = 1.5) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
    facet_grid(Model ~ Outcome, scales = "free_y") +
    theme_minimal(base_size = 12) +
    scale_fill_viridis_d(option = "C", end = 0.8) +
    labs(
        title = "Residual Density for PBC Data",
        subtitle = "serBilir, albumin, and Survival Outcomes (N(0,1) Scale)",
        x = "Residual", y = "Density", fill = "Loss Function"
    ) +
    theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_pbc_density)

p_cgd_density <- combined_residuals_long %>%
    filter(Dataset == "CGD") %>%
    ggplot(aes(x = Residual, fill = Loss)) +
    geom_density(alpha = 0.55, adjust = 1.5) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
    facet_grid(Model ~ Outcome, scales = "free_y") +
    theme_minimal(base_size = 12) +
    scale_fill_viridis_d(option = "C", end = 0.8) +
    labs(
        title = "Residual Density for CGD Data",
        subtitle = "Time, Event, and Survival Outcomes (N(0,1) Scale)",
        x = "Residual", y = "Density", fill = "Loss Function"
    ) +
    theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_cgd_density)
