# ==============================================================================
# Full R Code: CNN-LSTM with All Copula NLL Losses (Final Corrected Version)
# - tfprobability removed
# - tf$math$erf_inv changed to tf$math$erfinv
# - Conv1D padding="same" added for Timestep=1 data (CGD fix)
# ==============================================================================

# 0️⃣ Library Setup
# ==============================================================================
library(keras)
library(keras3)
library(tensorflow)
library(dplyr)
library(tidyr)
library(ggplot2)
library(copula)
library(gridExtra)
library(kableExtra)
library(viridis)
library(JM) # For pbc2.id and cgd datasets
set.seed(123)

# ==============================================================================
# Utility Functions
# ==============================================================================

# Uniform transform (sigmoid + clipping)
to_uniform_tf <- function(x) {
  u <- tf$math$sigmoid(tf$cast(x, tf$float32))
  tf$clip_by_value(u, 1e-6, 1 - 1e-6)
}

# Gaussian CDF to Z-space (CRITICAL FIX: using tf$math$erfinv)
u_to_z <- function(u) {
  u_clipped <- tf$clip_by_value(u, 1e-6, 1 - 1e-6)
  tf$math$sqrt(2.0) * tf$math$erfinv(2.0 * u_clipped - 1.0)
}

# Gaussian Copula Density (Log, 3D)
log_gaussian_copula_density <- function(u, R) {
  z <- u_to_z(u)
  eps <- 1e-6
  invR <- tf$linalg$inv(R + eps * tf$eye(3L))
  diff_mat <- invR - tf$eye(3L)
  z_col <- tf$reshape(z, tf$stack(list(tf$shape(z)[1], tf$shape(z)[2], 1L)))
  quad <- tf$matmul(tf$matmul(tf$transpose(z_col, perm = c(0L, 2L, 1L)), diff_mat), z_col)
  quad_term <- tf$reshape(quad, tf$stack(list(tf$shape(z)[1])))
  detR <- tf$linalg$det(R + eps * tf$eye(3L))
  -0.5 * quad_term - 0.5 * tf$math$log(detR + eps)
}


# ==============================================================================
# Copula Loss Functions (3D)
# ==============================================================================

# 1️⃣ Gaussian Copula NLL (TF-Native 3D)
copula_gaussian_loss <- function(y_true, y_pred) {
  y_pred <- tf$cast(y_pred, tf$float32)
  R_matrix <- tf$constant(diag(3) + 1e-6, dtype = tf$float32) 
  R <- tf$cast(R_matrix, tf$float32)
  u_pred <- to_uniform_tf(y_pred)
  log_c_density <- log_gaussian_copula_density(u_pred, R)
  nll <- -log_c_density
  tf$reduce_mean(nll)
}

# 2️⃣ Clayton Copula NLL Loss (3D)
copula_clayton_loss <- function(y_true, y_pred, theta_init = 1.5) {
  y_pred <- tf$cast(y_pred, tf$float32)
  theta <- tf$maximum(tf$cast(theta_init, tf$float32), 0.01)

  u_pred <- to_uniform_tf(y_pred)
  S <- tf$reduce_sum(tf$math$pow(u_pred, -theta), axis = 1L)

  log_term_const <- tf$math$log(1 + theta) + tf$math$log(1 + 2 * theta)
  log_term_prod <- - (theta + 1) * tf$reduce_sum(tf$math$log(u_pred), axis = 1L)
  log_term_power <- - (3 + 1 / theta) * tf$math$log(S - 2 + 1e-6)

  log_C_density <- log_term_const + log_term_prod + log_term_power
  nll <- -log_C_density
  tf$reduce_mean(nll)
}

# 3️⃣ Gumbel Copula NLL Loss (3D)
copula_gumbel_loss <- function(y_true, y_pred, theta_init = 2.0) {
  y_pred <- tf$cast(y_pred, tf$float32)
  theta <- tf$maximum(tf$cast(theta_init, tf$float32), 1.001)
  u_pred <- to_uniform_tf(y_pred)
  
  log_u <- -tf$math$log(u_pred)
  phi_u <- tf$math$pow(log_u, theta)
  sum_phi_u <- tf$reduce_sum(phi_u, axis = 1L)
  
  term1 <- -tf$math$pow(sum_phi_u, 1 / theta)
  term2 <- (1 / theta - 3) * tf$math$log(sum_phi_u + 1e-6)
  term3 <- tf$reduce_sum((theta - 1) * tf$math$log(log_u + 1e-6) - tf$math$log(u_pred + 1e-6), axis = 1L)
  
  inner_sum1 <- tf$math$pow(sum_phi_u, 2 / theta)
  inner_sum2 <- 3 * (theta - 1) * tf$math$pow(sum_phi_u, 1 / theta)
  inner_sum3 <- (2 * theta^2 - 3 * theta + 1)
  term4 <- tf$math$log(inner_sum1 + inner_sum2 + inner_sum3 + 1e-6)
  
  log_c_density <- term1 + term2 + term3 + term4
  nll <- -log_c_density
  tf$reduce_mean(nll)
}

# 4️⃣ Hybrid Clayton–Gumbel Loss (3D)
copula_hybrid_loss <- function(y_true, y_pred,
                               theta_clayton = 1.2,
                               theta_gumbel = 2.0,
                               alpha = 0.5) {
  loss_c <- copula_clayton_loss(y_true, y_pred, theta_clayton)
  loss_g <- copula_gumbel_loss(y_true, y_pred, theta_gumbel)
  tf$reduce_mean(alpha * loss_c + (1 - alpha) * loss_g)
}

# --- Custom Keras Layers (Placeholders) ---
LearnableClaytonActivation <- new_layer_class(
  classname="LearnableClaytonActivation",
  initialize=function(self, theta_init=1.0) { super$initialize(); self$theta <- self$add_weight(shape=list(), initializer=initializer_constant(theta_init), trainable=TRUE, name="theta") },
  call=function(self, inputs) { tf$identity(inputs) }
)
LearnableGumbelActivation <- new_layer_class(
  classname="LearnableGumbelActivation",
  initialize=function(self, theta_init=2.0) { super$initialize(); self$theta <- self$add_weight(shape=list(), initializer=initializer_constant(theta_init), trainable=TRUE, name="theta") },
  call=function(self, inputs) { tf$identity(inputs) }
)
LearnableClaytonGumbelHybrid <- new_layer_class(
  classname="LearnableClaytonGumbelHybrid",
  initialize=function(self, theta_c_init=1.0, theta_g_init=2.0, alpha_init=0.5) {
    super$initialize(); self$theta_c <- self$add_weight(shape=list(), initializer=initializer_constant(theta_c_init), trainable=TRUE, name="theta_c")
    self$theta_g <- self$add_weight(shape=list(), initializer=initializer_constant(theta_g_init), trainable=TRUE, name="theta_g")
    self$alpha <- self$add_weight(shape=list(), initializer=initializer_constant(alpha_init), trainable=TRUE, name="alpha")
  },
  call=function(self, inputs) { tf$identity(inputs) }
)


# ==============================================================================
# CNN-LSTM Model Builder & Trainer
# ==============================================================================

create_cnn_lstm <- function(type = c("clayton", "gumbel", "hybrid"), input_features) {
  type <- match.arg(type)
  
  # Determine current timesteps dynamically for Conv1D/Pooling logic
  # Checks the environment where 'train_and_evaluate' is called (or its caller)
  current_timesteps <- if(exists("timesteps_cgd", envir = parent.frame(2))) {
    get("timesteps_cgd", envir = parent.frame(2))
  } else if (exists("timesteps", envir = parent.frame(2))) {
    get("timesteps", envir = parent.frame(2))
  } else {
    10 # Default fallback
  }

  model <- keras_model_sequential() %>%
    layer_conv_1d(
      filters = 32, 
      kernel_size = 3, 
      activation = "relu",
      # CRITICAL FIX for Timestep=1: Use padding="same"
      padding = "same", 
      input_shape = c(current_timesteps, input_features)
    )
  
  # Conditional Max Pooling: Skip if timesteps=1
  if (current_timesteps > 1) {
    model <- model %>% layer_max_pooling_1d(pool_size = 2)
  }
  
  model <- model %>%
    layer_lstm(units = 64, return_sequences = FALSE) %>%
    layer_dropout(0.3)

  if (type == "clayton") model <- model %>% LearnableClaytonActivation()
  if (type == "gumbel") model <- model %>% LearnableGumbelActivation()
  if (type == "hybrid") model <- model %>% LearnableClaytonGumbelHybrid()

  model %>% layer_dense(units = 3, activation = "linear") # Output 3 N(0,1) variables
}

train_and_evaluate <- function(x_scaled, y_numeric, timesteps, features, model_types, model_names, loss_types) {
  all_results <- list(); all_residuals <- list()

  for (i in seq_along(model_types)) {
    for (loss in loss_types) {
      k_clear_session()
      cat("Training", model_names[i], "with", loss, "loss\n")
      # NOTE: timesteps and features are passed but model finds them in the parent env
      m <- create_cnn_lstm(model_types[i], input_features = dim(x_scaled)[3])

      current_loss_fn <- switch(
        loss,
        "copula_gaussian_loss" = copula_gaussian_loss,
        "copula_clayton_loss" = copula_clayton_loss,
        "copula_gumbel_loss" = copula_gumbel_loss,
        "copula_hybrid_loss" = copula_hybrid_loss
      )
      
      if(is.null(current_loss_fn)) { next }

      m %>% compile(optimizer = "adam", loss = current_loss_fn, metrics = "mae")

      m %>% fit(x_scaled, y_numeric, epochs = 10, batch_size = 32, verbose = 0, validation_split = 0.2)

      preds <- m %>% predict(x_scaled)
      residuals <- y_numeric - preds
      if(ncol(residuals) < 3) residuals <- cbind(residuals, NA) 

      res_df <- data.frame(Model = model_names[i], Loss = loss, ResidualY1 = residuals[,1], ResidualY2 = residuals[,2], ResidualS = residuals[,3])
      all_residuals[[paste0(model_names[i], "_", loss)]] <- res_df

      all_results[[paste0(model_names[i], "_", loss)]] <- data.frame(
        Model = model_names[i], Loss = loss, MeanResidual1 = mean(residuals[,1]), SDResidual1 = sd(residuals[,1]),
        MeanResidual2 = mean(residuals[,2]), SDResidual2 = sd(residuals[,2]),
        MeanResidualS = mean(residuals[,3]), SDResidualS = sd(residuals[,3])
      )
    }
  }
  return(list(results = do.call(rbind, all_results), residuals = do.call(rbind, all_residuals)))
}


# ==============================================================================
# PART 1: SIMULATION STUDY (3-Outcome)
# ==============================================================================

cat("================================\n")
cat("SIMULATION STUDY\n")
cat("================================\n")

n <- 500; timesteps <- 10; features <- 30
x_data_array <- array(runif(n*timesteps*features), dim=c(n,timesteps,features))
x_scaled <- (x_data_array - mean(x_data_array)) / sd(x_data_array)

# Simulate Y1, Y2, and survival S (Latent variables)
beta_Y1 <- rnorm(features); beta_Y2 <- rnorm(features)
rbf_kernel <- function(x_mat) apply(x_mat,1,mean)
x_data_matrix <- apply(x_data_array, c(1,3), mean)
Y1 <- as.numeric(x_data_matrix %*% beta_Y1 + 2*rbf_kernel(x_data_matrix) + rnorm(n,0,0.1))
Y2 <- as.numeric(x_data_matrix %*% beta_Y2 + 1.5*rbf_kernel(x_data_matrix) + rnorm(n,0,0.1))
S_latent <- -log(runif(n)) / (exp(Y1 + Y2)) # S_latent is the third outcome

# For the model, we use the continuous variables directly transformed to N(0,1)
y_numeric <- as.matrix(sapply(data.frame(Y1, Y2, S=S_latent), function(x) qnorm(rank(x)/(length(x)+1))))

# Train simulation models
model_types <- c("clayton", "gumbel", "hybrid")
model_names <- c("Clayton", "Gumbel", "Clayton-Gumbel")
loss_types <- c("copula_gaussian_loss", "copula_clayton_loss", "copula_gumbel_loss", "copula_hybrid_loss")
sim_results <- train_and_evaluate(x_scaled, y_numeric, timesteps, features, model_types, model_names, loss_types)

cat("\nSimulation Residual Summary:\n")
print(kable(sim_results$results, digits = 3, caption = "Simulation Residual Summary") %>% kable_styling(full_width = FALSE))

# ==============================================================================
# PART 2: PBC DATA (3-Outcome)
# ==============================================================================

cat("\n\n================================\n")
cat("REAL DATA: PBC Study\n")
cat("================================\n")

data("pbc2.id", package="JM"); pbc <- pbc2.id
pbc$serBilir <- as.numeric(pbc$serBilir); pbc$albumin <- as.numeric(pbc$albumin); pbc$years <- as.numeric(pbc$years); pbc$status <- as.numeric(pbc$status)

surv_summary <- pbc %>% group_by(id) %>% summarise(surv_time=max(years,na.rm=TRUE), event=as.integer(any(status %in% c(1,2)))) %>% ungroup()
subject_ids <- head(surv_summary$id, 500); pbc <- pbc %>% filter(id %in% subject_ids)
timesteps <- 10; numeric_features <- head(setdiff(names(pbc), c("id","years","status","drug","sex","ascites","hepatomegaly","spiders","edema","histol")), 30)
long_data <- pbc[, c("id","years",numeric_features)]; long_data <- long_data[order(long_data$id,long_data$years),]

# Prepare X-array
subject_list <- split(long_data, long_data$id)
pad_subject <- function(df, features, tsteps) {
  mat <- as.matrix(df[, features, drop=FALSE])
  if(nrow(mat) >= tsteps) mat[1:tsteps,] else rbind(mat, matrix(0, nrow=tsteps-nrow(mat), ncol=ncol(mat)))
}
x_array <- array(unlist(lapply(subject_list, pad_subject, numeric_features, timesteps)), dim=c(length(subject_list),timesteps,length(numeric_features)))
for(j in 1:dim(x_array)[3]){ col_data <- x_array[,,j]; col_data[is.na(col_data)] <- mean(col_data[col_data!=0], na.rm=TRUE); x_array[,,j] <- col_data }
x_scaled <- (x_array - mean(x_array, na.rm=TRUE)) / sd(x_array, na.rm=TRUE)
x_scaled[is.na(x_scaled)] <- 0

# Prepare Y (Last serBilir, Last albumin, Survival Time)
y_data_df <- surv_summary %>% left_join(long_data %>% group_by(id) %>% summarise(Y_serBilir=last(serBilir), Y_albumin=last(albumin)), by="id") %>% dplyr::select(Y_serBilir,Y_albumin,S=surv_time) %>% na.omit()
y_numeric <- as.matrix(sapply(y_data_df, function(x) qnorm(rank(x)/(length(x)+1))))
x_scaled <- x_scaled[1:nrow(y_numeric), , ] # Align X and Y

# Train PBC models
real_results <- train_and_evaluate(x_scaled, y_numeric, timesteps, length(numeric_features), model_types, model_names, loss_types)

cat("\nReal PBC Residual Summary:\n")
print(kable(real_results$results, digits = 3, caption = "Real PBC Residual Summary") %>% kable_styling(full_width = FALSE))


# ==============================================================================
# PART 3: CANCER DATA (3-Outcome, Timesteps=1)
# ==============================================================================

cat("\n\n================================\n")
cat("REAL DATA: Lung Cancer Study\n")
cat("================================\n")

# Load cancer survival data
data(cancer, package = "survival")
df <- cancer

# Clean and select features
numeric_covs <- c("age", "ph.karno", "pat.karno", "wt.loss")
categorical_covs <- c("sex", "meal.cal", "inst")  # will one-hot encode later
df <- df[, c("time", "status", numeric_covs, categorical_covs)]
df <- df[complete.cases(df), ]

# Convert categorical to numeric indicators
X <- model.matrix(~ 0 + sex + meal.cal + inst, data = df)
X <- cbind(df[, numeric_covs], X)

# Prepare 3D array for CNN-LSTM input (timesteps = 1 for cross-sectional data)
timesteps_cancer <- 1
x_array <- array(as.matrix(X), dim = c(nrow(X), timesteps_cancer, ncol(X)))

# Normalize features
x_scaled <- (x_array - mean(x_array)) / sd(x_array)

# Prepare 3 outcome variables:
#   Y1: survival event indicator
#   Y2: weighted performance index (e.g., ph.karno - wt.loss)
#   Y3: survival time
y_df <- data.frame(
  Y1 = df$status,
  Y2 = with(df, ph.karno - wt.loss),
  Y3 = df$time
)

# Gaussianize for copula modeling
y_numeric <- as.matrix(sapply(y_df, function(x) qnorm(rank(x) / (length(x) + 1))))

# Train models (copula + CNN-LSTM)
features_cancer <- ncol(X)
cancer_results <- train_and_evaluate(
  x_scaled,
  y_numeric,
  timesteps_cancer,
  features_cancer,
  model_types,
  model_names,
  loss_types
)

# Display residual summaries
cat("\nReal Cancer Residual Summary:\n")
print(
  kable(cancer_results$results, digits = 3, caption = "Real Cancer Residual Summary") %>%
    kable_styling(full_width = FALSE)
)
# ==============================================================================
# PART 4: RESIDUAL ANALYSIS AND PLOTTING (Simulated + PBC + Cancer)
# ==============================================================================

library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(kableExtra)

cat("\n\n================================\n")
cat("RESIDUAL ANALYSIS AND PLOTTING\n")
cat("================================\n")

# 1️⃣ Transform Residuals into Long Format

# Simulation Residuals
sim_residuals_long <- sim_results$residuals %>%
  tidyr::pivot_longer(
    cols = c(ResidualY1, ResidualY2, ResidualS),
    names_to = "Outcome",
    values_to = "Residual"
  ) %>%
  mutate(
    Outcome = gsub("Residual", "", Outcome),
    Dataset = "Simulated"
  )

# PBC Residuals
pbc_residuals_long <- real_results$residuals %>%
  tidyr::pivot_longer(
    cols = c(ResidualY1, ResidualY2, ResidualS),
    names_to = "Outcome",
    values_to = "Residual"
  ) %>%
  mutate(
    Outcome = gsub("ResidualY1", "serBilir", Outcome),
    Outcome = gsub("ResidualY2", "albumin", Outcome),
    Outcome = gsub("ResidualS", "Survival", Outcome),
    Dataset = "PBC"
  )

# Cancer Residuals
cancer_residuals_long <- cancer_results$residuals %>%
  pivot_longer(
    cols = c(ResidualY1, ResidualY2, ResidualS),
    names_to = "Outcome",
    values_to = "Residual"
  ) %>%
  mutate(
    Outcome = gsub("ResidualY1", "Event", Outcome),
    Outcome = gsub("ResidualY2", "Performance", Outcome),
    Outcome = gsub("ResidualS", "Time", Outcome),
    Dataset = "Cancer"
  )

# 2️⃣ Combine all residual data
combined_residuals_long <- bind_rows(
  sim_residuals_long,
  pbc_residuals_long,
  cancer_residuals_long
)

# 3️⃣ Density Plot: Residuals by Model and Outcome
p_combined_density <- ggplot(combined_residuals_long, aes(x = Residual, fill = Loss)) +
  geom_density(alpha = 0.55, adjust = 1.2) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(Dataset + Model ~ Outcome, scales = "free") +
  theme_minimal(base_size = 10) +
  scale_fill_viridis_d(option = "C", end = 0.8) +
  labs(
    title = "Residual Density Comparison Across Datasets (Sim, PBC, Cancer)",
    subtitle = "A good model should produce residuals centered around zero (N(0,1) scale)",
    x = "Residual (Standard Normal Scale)", y = "Density", fill = "Loss Function"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 12),
    legend.position = "bottom",
    strip.text = element_text(size = 9)
  )

print(p_combined_density)

# 4️⃣ Boxplot: Residual spread comparison
p_combined_box <- ggplot(combined_residuals_long, aes(x = Loss, y = Residual, fill = Loss)) +
  geom_boxplot(alpha = 0.6, outlier.size = 0.5, width = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(Dataset + Model ~ Outcome, scales = "free_y") +
  theme_minimal(base_size = 10) +
  scale_fill_viridis_d(option = "C", end = 0.8) +
  labs(
    title = "Residual Spread Across Datasets (Sim, PBC, Cancer)",
    subtitle = "Closer median to zero and tighter IQR indicates better fit",
    x = "Loss Function", y = "Residual (Standard Normal Scale)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    strip.text = element_text(size = 9, face = "bold"),
    legend.position = "none"
  )

print(p_combined_box)

# 5️⃣ Final Combined Summary Table
all_results_combined <- bind_rows(
  sim_results$results %>% mutate(Dataset = "Simulated"),
  real_results$results %>% mutate(Dataset = "PBC"),
  cancer_results$results %>% mutate(Dataset = "Cancer")
)

cat("\n\n================================\n")
cat("COMBINED RESULTS SUMMARY (Mean/SD of Residuals)\n")
cat("================================\n")

print(
  kable(all_results_combined, digits = 3, caption = "Combined Residual Summaries (Mean/SD)") %>%
    kable_styling(full_width = FALSE) %>%
    group_rows("Simulated", 1, nrow(sim_results$results)) %>%
    group_rows("PBC", nrow(sim_results$results) + 1, nrow(sim_results$results) + nrow(real_results$results)) %>%
    group_rows("Cancer", nrow(sim_results$results) + nrow(real_results$results) + 1, nrow(all_results_combined))
)

# ------------------------------------------------------------------------------

# 6️⃣ Individual dataset residual densities

# Simulated
p_sim_density <- combined_residuals_long %>%
  filter(Dataset == "Simulated") %>%
  ggplot(aes(x = Residual, fill = Loss)) +
  geom_density(alpha = 0.55, adjust = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(Model ~ Outcome, scales = "free_y") +
  theme_minimal(base_size = 12) +
  scale_fill_viridis_d(option = "C", end = 0.8) +
  labs(
    title = "Residual Density for Simulated Data",
    subtitle = "Y1, Y2, and Survival Outcomes (N(0,1) Scale)",
    x = "Residual", y = "Density", fill = "Loss Function"
  ) +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_sim_density)

# PBC
p_pbc_density <- combined_residuals_long %>%
  filter(Dataset == "PBC") %>%
  ggplot(aes(x = Residual, fill = Loss)) +
  geom_density(alpha = 0.55, adjust = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(Model ~ Outcome, scales = "free_y") +
  theme_minimal(base_size = 12) +
  scale_fill_viridis_d(option = "C", end = 0.8) +
  labs(
    title = "Residual Density for PBC Data",
    subtitle = "serBilir, albumin, and Survival Outcomes (N(0,1) Scale)",
    x = "Residual", y = "Density", fill = "Loss Function"
  ) +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_pbc_density)

# Cancer
p_cancer_density <- combined_residuals_long %>%
  filter(Dataset == "Cancer") %>%
  ggplot(aes(x = Residual, fill = Loss)) +
  geom_density(alpha = 0.55, adjust = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(Model ~ Outcome, scales = "free_y") +
  theme_minimal(base_size = 12) +
  scale_fill_viridis_d(option = "C", end = 0.8) +
  labs(
    title = "Residual Density for Cancer Data",
    subtitle = "Survival Event indicator, Weighted Performance Index, Survival Time",
    x = "Residual", y = "Density", fill = "Loss Function"
  ) +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

print(p_cancer_density)
