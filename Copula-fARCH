# ============================================
#  fARCH vs Copula-fARCH Simulation (100 Iter)
# ============================================

# --- Clean Environment ---
rm(list = ls()); gc()

# --- Load Libraries ---
library(sde)
library(fda)
library(fdapace)
library(MASS)
library(ggplot2)
library(copula)
library(forecast)
library(DEoptim)
library(Matrix)
library(tseries)
library(reshape2)
library(parallel)
library(patchwork)

# --- Parameters ---
L <- 350          # Intraday points per day
N <- 100          # Number of days
p <- 2            # Number of FPCs
nbasis <- 15      # Number of B-spline basis functions
norder <- 4       # Basis order
lambda <- 1e-4    # Smoothing parameter
itermax <- 200
n_iter <- 100    # Number of simulation iterations


# ====================================
# --- fARCH Estimation Function ---
# ====================================
estimate_farch <- function(y_old, L, p, nbasis = 15, norder = 4) {
  N <- ncol(y_old)
  sigma_out_squared <- matrix(0, N - 2, L)
  basis <- create.bspline.basis(rangeval = c(0, 1), nbasis = nbasis, norder = norder)
  fd_par_obj <- fdPar(basis, lambda = 1e-4, Lfdobj = 2)
  times <- seq(0, 1, length.out = L)
  
  for (out in 2:(N - 1)) {
    y <- y_old[, -out, drop = FALSE]
    y_sq_fdsmooth <- smooth.basis(times, y^2, fdParobj = fd_par_obj)
    functional_y_squared <- y_sq_fdsmooth$fd
    principal_components <- pca.fd(fdobj = functional_y_squared, nharm = p)
    eigenfunctions <- principal_components$harmonics
    mean_fd <- mean.fd(functional_y_squared)
    
    Z <- matrix(0, p, ncol(y))
    for (i in 1:p) {
      for (k in 1:ncol(y)) {
        Z[i, k] <- inprod(fd(coef = functional_y_squared$coefs[, k, drop = FALSE],
                             basisobj = basis), eigenfunctions[i]) -
          inprod(mean_fd, eigenfunctions[i])
      }
    }
    
    part1 <- part2 <- matrix(0, p, p)
    for (k in 2:ncol(Z)) {
      part1 <- part1 + Z[, k] %*% t(Z[, k - 1])
      part2 <- part2 + Z[, k - 1] %*% t(Z[, k - 1])
    }
    M <- part1 %*% solve(part2)
    
    eigenvector <- lapply(1:p, function(i) eval.fd(times, eigenfunctions[i]))
    beta_matrix_estimated <- Reduce(`+`, lapply(1:p, function(k) {
      Reduce(`+`, lapply(1:p, function(ell) {
        M[k, ell] * eigenvector[[k]] %*% t(eigenvector[[ell]])
      }))
    }))
    
    beta_hat <- function(x) t(beta_matrix_estimated %*% t(x)) / L
    m_hat <- t(as.matrix(eval.fd(times, mean_fd)))
    estimated_delta <- m_hat - beta_hat(m_hat)
    
    y_test <- matrix(y_old[, out - 1]^2, nrow = 1)
    sigma_out_squared[out - 1, ] <- estimated_delta + beta_hat(y_test)
  }
  return(sigma_out_squared)
}


# =========================================
# --- Copula-fARCH Estimation Function ---
# =========================================
estimate_cfarch <- function(y_old, L, p, nbasis = 15, norder = 4, lambda = 1e-4) {
  N <- ncol(y_old)
  sigma_out_squared <- matrix(0, N - 2, L)
  basis <- create.bspline.basis(c(0, 1), nbasis = nbasis, norder = norder)
  fd_par_obj <- fdPar(basis, lambda = lambda, Lfdobj = 2)
  times <- seq(0, 1, length.out = L)
  
  for (out in 2:(N - 1)) {
    y <- y_old[, -out, drop = FALSE]
    
    y_sq_fdsmooth <- smooth.basis(times, y^2, fdParobj = fd_par_obj)
    functional_y_squared <- y_sq_fdsmooth$fd
    mean_fd <- mean.fd(functional_y_squared)
    pca_obj <- pca.fd(fdobj = functional_y_squared, nharm = p)
    eigenfunctions <- pca_obj$harmonics
    
    Z <- matrix(0, p, ncol(y))
    for (i in 1:p) {
      for (k in 1:ncol(y)) {
        Z[i, k] <- inprod(fd(coef = functional_y_squared$coefs[, k, drop = FALSE],
                             basisobj = basis), eigenfunctions[i]) -
          inprod(mean_fd, eigenfunctions[i])
      }
    }
    
    u_data <- pobs(t(Z))
    sims_list <- list()
    n_sim <- ncol(Z)
    
    for (cop_type in c("gaussian", "clayton")) {
      fit_cop <- tryCatch({
        cop_obj <- switch(cop_type,
                          "gaussian" = normalCopula(dim = p, dispstr = "un"),
                          "clayton"  = claytonCopula(dim = p))
        fitCopula(cop_obj, u_data, method = "ml")
      }, error = function(e) NULL)
      
      if (!is.null(fit_cop)) {
        sim_cop <- rCopula(n_sim, fit_cop@copula)
        sims_list[[length(sims_list) + 1]] <- qnorm(sim_cop)
      }
    }
    
    Z_used <- if (length(sims_list) > 0) {
      t(Reduce("+", sims_list) / length(sims_list))
    } else {
      t(Z)
    }
    
    part1 <- part2 <- matrix(0, p, p)
    for (k in 2:ncol(Z_used)) {
      part1 <- part1 + Z_used[, k] %*% t(Z_used[, k - 1])
      part2 <- part2 + Z_used[, k - 1] %*% t(Z_used[, k - 1])
    }
    M <- part1 %*% solve(part2)
    
    eigenvector <- lapply(1:p, function(i) eval.fd(times, eigenfunctions[i]))
    beta_matrix_estimated <- Reduce(`+`, lapply(1:p, function(k) {
      Reduce(`+`, lapply(1:p, function(ell) {
        M[k, ell] * eigenvector[[k]] %*% t(eigenvector[[ell]])
      }))
    }))
    
    beta_hat <- function(x) t(beta_matrix_estimated %*% t(x)) / L
    m_hat <- t(as.matrix(eval.fd(times, mean_fd)))
    estimated_delta <- m_hat - beta_hat(m_hat)
    
    y_test <- matrix(y_old[, out - 1]^2, nrow = 1)
    sigma_out_squared[out - 1, ] <- estimated_delta + beta_hat(y_test)
  }
  
  return(sigma_out_squared)
}


# ====================================
# --- Utility Functions ---
# ====================================
log_stabilize <- function(mat, epsilon = 1e-6) {
  log_mat <- log(mat + epsilon)
  exp(log_mat)
}

evaluate_model <- function(est, proxy) {
  error <- est - proxy
  rmse <- sqrt(mean(error^2, na.rm = TRUE))
  mae  <- mean(abs(error), na.rm = TRUE)
  mape <- mean(abs((proxy - est)/ifelse(proxy==0, NA, proxy)), na.rm = TRUE) * 100
  log_est <- log1p(pmax(est, 0))
  log_proxy <- log1p(pmax(proxy, 0))
  msle <- mean((log_est - log_proxy)^2, na.rm = TRUE)
  corr <- mean(sapply(1:nrow(est), function(i) cor(est[i, ], proxy[i, ], use = "complete.obs")), na.rm = TRUE)
  return(list(RMSE=rmse, MAE=mae, MAPE=mape, MSLE=msle, Corr=corr))
}


# ====================================
# --- Single Simulation Function ---
# ====================================
run_single_sim <- function(iter) {
  set.seed(100 + iter)
  
  # Simulate volatility and returns
  volatility <- numeric(L + 1)
  volatility[1] <- 0.5
  alpha0 <- 0.001; alpha1 <- 0.25; beta1 <- 0.74; shock_scale <- 0.6
  for (t in 2:(L + 1)) {
    shock <- rnorm(1, mean = 0, sd = shock_scale)
    volatility[t] <- sqrt(pmax(alpha0 + alpha1 * volatility[t - 1]^2 + beta1 * shock^2, 1e-6))
  }
  ar_coef <- 0.95
  returns <- matrix(0, nrow = L + 1, ncol = N)
  for (i in 1:N) {
    ar_process <- numeric(L + 1)
    ar_process[1] <- rnorm(1, sd = volatility[1])
    for (t in 2:(L + 1)) {
      epsilon <- rnorm(1, sd = volatility[t])
      ar_process[t] <- ar_coef * ar_process[t - 1] + epsilon
    }
    returns[, i] <- ar_process
  }
  returns_use <- returns[-1, ]
  
  # Estimate models
  sigma_farch <- estimate_farch(returns_use, L, p, nbasis, norder)
  sigma_cfarch <- estimate_cfarch(returns_use, L, p, nbasis, norder)
  
  # Log-stabilize
  pred_farch <- log_stabilize(sigma_farch)
  pred_cfarch <- log_stabilize(sigma_cfarch)
  true_vol_eval <- log_stabilize(t(returns_use^2))
  true_vol_eval <- true_vol_eval[1:nrow(pred_farch), ]
  
  # Evaluate
  eval_farch  <- evaluate_model(pred_farch, true_vol_eval)
  eval_cfarch <- evaluate_model(pred_cfarch, true_vol_eval)
  
  return(data.frame(
    Iter = iter,
    RMSE_fARCH = eval_farch$RMSE,
    RMSE_CfARCH = eval_cfarch$RMSE,
    Corr_fARCH = eval_farch$Corr,
    Corr_CfARCH = eval_cfarch$Corr
  ))
}


# ====================================
# --- Parallel Simulation (100x) ---
# ====================================
n_cores <- max(1, detectCores() - 1)
cl <- makeCluster(n_cores)

# Export everything needed
clusterExport(cl, list(
  "estimate_farch", "estimate_cfarch", "log_stabilize", "evaluate_model",
  "L", "N", "p", "nbasis", "norder", "lambda"
))
clusterEvalQ(cl, {
  library(sde); library(fda); library(fdapace); library(MASS)
  library(ggplot2); library(copula); library(forecast)
  library(DEoptim); library(Matrix); library(tseries); library(reshape2)
})

# Run
results_list <- parLapply(cl, 1:n_iter, run_single_sim)
stopCluster(cl)

# Combine Results
results_df <- do.call(rbind, results_list)
print(summary(results_df))

# --- Visualization of RMSE comparison ---
results_melt <- melt(results_df[, c("RMSE_fARCH", "RMSE_CfARCH")])
ggplot(results_melt, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot(outlier.shape = NA) +
  labs(title = "RMSE Comparison: fARCH vs Copula-fARCH",
       x = "Model", y = "RMSE") +
  theme_minimal() +
  theme(legend.position = "none")


# ==========================
# --- Summary Table ---
# ==========================
library(dplyr)
library(knitr)

summary_table <- results_df %>%
  summarise(
    Mean_RMSE_fARCH = mean(RMSE_fARCH, na.rm = TRUE),
    SD_RMSE_fARCH   = sd(RMSE_fARCH, na.rm = TRUE),
    Mean_RMSE_CfARCH = mean(RMSE_CfARCH, na.rm = TRUE),
    SD_RMSE_CfARCH   = sd(RMSE_CfARCH, na.rm = TRUE),
    Mean_Corr_fARCH = mean(Corr_fARCH, na.rm = TRUE),
    SD_Corr_fARCH   = sd(Corr_fARCH, na.rm = TRUE),
    Mean_Corr_CfARCH = mean(Corr_CfARCH, na.rm = TRUE),
    SD_Corr_CfARCH   = sd(Corr_CfARCH, na.rm = TRUE)
  )

print(summary_table)



# ==========================
# --- Visualization ---
# ==========================
library(ggplot2)
library(reshape2)

# Melt the RMSE and Corr values for comparison
results_melt <- results_df %>%
  select(RMSE_fARCH, RMSE_CfARCH, Corr_fARCH, Corr_CfARCH) %>%
  melt(variable.name = "Metric", value.name = "Value")

# Add group columns for easier labeling
results_melt$Type <- ifelse(grepl("RMSE", results_melt$Metric), "RMSE", "Correlation")
results_melt$Model <- ifelse(grepl("CfARCH", results_melt$Metric), "Copula-fARCH", "fARCH")

# --- RMSE Boxplot ---
ggplot(filter(results_melt, Type == "RMSE"),
       aes(x = Model, y = Value, fill = Model)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = quantile(results_melt$Value[results_melt$Type == "RMSE"], c(0.05, 0.95))) +
  labs(title = "RMSE Comparison (fARCH vs Copula-fARCH)",
       x = "", y = "RMSE") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 14))

# --- Correlation Boxplot ---
ggplot(filter(results_melt, Type == "Correlation"),
       aes(x = Model, y = Value, fill = Model)) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = quantile(results_melt$Value[results_melt$Type == "Correlation"], c(0.05, 0.95))) +
  labs(title = "Correlation Comparison (fARCH vs Copula-fARCH)",
       x = "", y = "Correlation") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none",
        plot.title = element_text(face = "bold", size = 14))


# --- Combined Summary Plot ---
summary_long <- results_melt %>%
  group_by(Model, Type) %>%
  summarise(
    Mean = mean(Value, na.rm = TRUE),
    SD = sd(Value, na.rm = TRUE)
  )

ggplot(summary_long, aes(x = Model, y = Mean, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD),
                position = position_dodge(width = 0.7), width = 0.2) +
  labs(title = "Mean ± SD of RMSE and Correlation across Models",
       x = "Model", y = "Value", fill = "Metric Type") +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 14))

