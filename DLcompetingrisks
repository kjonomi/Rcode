# ================================================================
# 0️⃣ Simulation Sudy
# ================================================================
library(survival)
library(dplyr)
library(tidyr)
library(keras)
library(tensorflow)
library(Hmisc)
library(boot)
library(cmprsk)
library(ggplot2)
library(knitr)

# ================================================================
# 1️⃣ Simulation parameters
# ================================================================
n_sim <- 10      # number of simulations
n <- 1000        # sample size
B_boot <- 50     # bootstrap iterations
covariates <- c("x1","x2","x3","x4")
times_eval <- seq(0, 50, by=1)

# ================================================================
# 2️⃣ Copula helper functions (Gaussian/Clayton/Gumbel)
# ================================================================
to_uniform_tf <- function(x){
  u <- tf$math$sigmoid(tf$cast(x, tf$float32))
  tf$clip_by_value(u, 1e-6, 1-1e-6)
}

copula_gaussian_loss <- function(y_true, y_pred){
  rho <- tf$constant(0.5, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  z <- tf$sqrt(2) * tf$math$erfinv(2*u - 1)
  z1 <- z[,1]; z2 <- z[,2]
  detR <- 1 - rho^2
  invR <- 1 / detR
  quad <- invR * (z1^2 + z2^2 - 2*rho*z1*z2)
  loss_term <- -0.5*quad - 0.5*tf$math$log(detR)
  -tf$reduce_mean(loss_term)
}

copula_clayton_loss <- function(y_true, y_pred){
  theta <- tf$constant(1.5, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  S <- tf$reduce_sum(u^(-theta), axis=1L)
  log_c <- tf$math$log(1+theta) - (theta+1)*tf$reduce_sum(tf$math$log(u), axis=1L) - (2 + 1/theta)*tf$math$log(S - 1 + 1e-6)
  -tf$reduce_mean(log_c)
}

copula_gumbel_loss <- function(y_true, y_pred){
  theta <- tf$constant(2.0, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  log_u <- -tf$math$log(u)
  phi <- log_u^theta
  S <- tf$reduce_sum(phi, axis=1L)
  log_C <- -S^(1/theta)
  log_c <- log_C +
    (1/theta - 1) * tf$math$log(S + 1e-6) +
    tf$reduce_sum((theta-1)*tf$math$log(log_u + 1e-6) - tf$math$log(u + 1e-6), axis=1L) +
    tf$math$log(1 + (theta-1)*S^(-1/theta))
  -tf$reduce_mean(log_c)
}

# ================================================================
# 3️⃣ CNN-LSTM model builder
# ================================================================
create_model <- function(loss_fn, n_features=length(covariates), n_causes=2){
  inputs <- layer_input(shape=c(1,n_features))
  outputs <- inputs %>%
    layer_conv_1d(filters=16, kernel_size=1, activation="relu") %>%
    layer_lstm(16) %>%
    layer_dense(16, activation="relu") %>%
    layer_dense(n_causes, activation="sigmoid")
  
  model <- keras_model(inputs=inputs, outputs=outputs)
  model %>% compile(
    loss=loss_fn,
    optimizer=optimizer_adam(0.001)
  )
  return(model)
}

# ================================================================
# 4️⃣ Simulation loop
# ================================================================
set.seed(123)
cindex_results_list <- list()
cif_results_list <- list()

for(sim in 1:n_sim){
  cat("Simulation:", sim, "\n")
  
  # ---------- Synthetic strong-signal competing-risk data ----------
  df <- data.frame(
    id = 1:n,
    x1 = rnorm(n),
    x2 = rnorm(n),
    x3 = rnorm(n),
    x4 = rnorm(n)
  )
  
  lp1 <- 2*df$x1 - df$x2 + 1.5*df$x3
  lp2 <- -1*df$x1 + 2*df$x2 - df$x4
  baseline_hazard <- 0.02
  df$time1 <- -log(runif(n)) / (baseline_hazard * exp(lp1))
  df$time2 <- -log(runif(n)) / (baseline_hazard * exp(lp2))
  
  df$event <- ifelse(df$time1 < df$time2, 1,
                     ifelse(df$time2 < df$time1, 2, 0))
  df$time <- pmin(df$time1, df$time2)
  
  # ---------- Train/test split ----------
  idx_train <- sample(seq_len(n), floor(0.8*n))
  df_train <- df[idx_train, ]
  df_test  <- df[-idx_train, ]
  
  X_train <- array(as.matrix(df_train[,covariates]), dim=c(nrow(df_train),1,length(covariates)))
  X_test  <- array(as.matrix(df_test[,covariates]), dim=c(nrow(df_test),1,length(covariates)))
  
  df_train$event1 <- ifelse(df_train$event==1,1,0)
  df_train$event2 <- ifelse(df_train$event==2,1,0)
  y_train_cr <- as.matrix(cbind(1-(df_train$event1+df_train$event2), df_train$event1, df_train$event2))
  
  df_test$event1 <- ifelse(df_test$event==1,1,0)
  df_test$event2 <- ifelse(df_test$event==2,1,0)
  y_test_cr <- as.matrix(cbind(1-(df_test$event1+df_test$event2), df_test$event1, df_test$event2))
  
  # ---------- Build and train Copula-CR models ----------
  model_gauss <- create_model(copula_gaussian_loss)
  model_clayton <- create_model(copula_clayton_loss)
  model_gumbel <- create_model(copula_gumbel_loss)
  
  model_gauss %>% fit(X_train, y_train_cr, epochs=5, batch_size=32, verbose=0)
  model_clayton %>% fit(X_train, y_train_cr, epochs=5, batch_size=32, verbose=0)
  model_gumbel %>% fit(X_train, y_train_cr, epochs=5, batch_size=32, verbose=0)
  
  pretrained_all <- list(
    copula_gauss=model_gauss,
    copula_clayton=model_clayton,
    copula_gumbel=model_gumbel
  )
  
  # ---------- Bootstrap C-index ----------
  cindex_cause_boot_fn <- function(data, indices, model_name, cause=1){
    d <- data[indices, ]
    y_true <- d$event
    if(sum(y_true==cause)<2) return(NA)
    
    m <- pretrained_all[[model_name]]
    Xd <- array(as.matrix(d[,covariates]), dim=c(nrow(d),1,length(covariates)))
    p <- m %>% predict(Xd)
    score <- p[,cause]
    
    rcorr.cens(score, Surv(d$time, ifelse(y_true==cause,1,0)))["C Index"]
  }
  
  ci_safe <- function(b){ 
    if(all(is.na(b$t))||sd(b$t,na.rm=TRUE)==0) c(NA,NA) else boot.ci(b,type="perc")$percent[4:5] 
  }
  
  boot_models <- c("copula_gauss","copula_clayton","copula_gumbel")
  boot_results_c1 <- lapply(boot_models, function(m) boot(df_test,function(d,i) cindex_cause_boot_fn(d,i,m,cause=1),R=B_boot))
  boot_results_c2 <- lapply(boot_models, function(m) boot(df_test,function(d,i) cindex_cause_boot_fn(d,i,m,cause=2),R=B_boot))
  
  summary_cause_ci <- data.frame(
    Simulation=sim,
    Model=c("Copula Gaussian","Copula Clayton","Copula Gumbel"),
    C_index_Cause1 = sapply(boot_results_c1,function(b) mean(b$t,na.rm=TRUE)),
    CI_lower_Cause1 = sapply(boot_results_c1,function(b) ci_safe(b)[1]),
    CI_upper_Cause1 = sapply(boot_results_c1,function(b) ci_safe(b)[2]),
    C_index_Cause2 = sapply(boot_results_c2,function(b) mean(b$t,na.rm=TRUE)),
    CI_lower_Cause2 = sapply(boot_results_c2,function(b) ci_safe(b)[1]),
    CI_upper_Cause2 = sapply(boot_results_c2,function(b) ci_safe(b)[2])
  )
  
  cindex_results_list[[sim]] <- summary_cause_ci
  
  # ---------- Compute CIF for each model ----------
  compute_cif <- function(model, df, times){
    Xd <- array(as.matrix(df[,covariates]), dim=c(nrow(df),1,length(covariates)))
    p <- model %>% predict(Xd)
    mean_cif1 <- sapply(times, function(t) mean(p[,1])) # placeholder: static probability
    mean_cif2 <- sapply(times, function(t) mean(p[,2]))
    data.frame(Time=times, CIF1=mean_cif1, CIF2=mean_cif2, Model=deparse(substitute(model)))
  }
  
  cif_results_list[[sim]] <- rbind(
    compute_cif(model_gauss, df_test, times_eval),
    compute_cif(model_clayton, df_test, times_eval),
    compute_cif(model_gumbel, df_test, times_eval)
  )
}

# ================================================================
# 5️⃣ Aggregate results
# ================================================================
cindex_all <- do.call(rbind, cindex_results_list)
cif_all <- do.call(rbind, cif_results_list)

# ---------- Plot CIF ----------
ggplot(cif_all, aes(x=Time, y=CIF1, color=Model)) +
  geom_line() +
  labs(title="Predicted CIF for Cause 1", y="CIF", x="Time") +
  theme_minimal()

ggplot(cif_all, aes(x=Time, y=CIF2, color=Model)) +
  geom_line() +
  labs(title="Predicted CIF for Cause 2", y="CIF", x="Time") +
  theme_minimal()

# ---------- Show C-index summary ----------
cindex_all

# ---------- Pivot to long format ----------
cindex_long <- cindex_all %>%
  pivot_longer(
    cols = c(C_index_Cause1, C_index_Cause2),
    names_to = "Cause",
    values_to = "C_index"
  ) %>%
  mutate(
    Cause = ifelse(Cause == "C_index_Cause1", "Cause 1", "Cause 2")
  )

# ---------- Summarize mean and CI per model and cause ----------
cindex_summary_table <- cindex_long %>%
  group_by(Model, Cause) %>%
  summarise(
    Mean_C_index = mean(C_index, na.rm = TRUE),
    CI_lower = mean(ifelse(Cause=="Cause 1", CI_lower_Cause1, CI_lower_Cause2), na.rm = TRUE),
    CI_upper = mean(ifelse(Cause=="Cause 1", CI_upper_Cause1, CI_upper_Cause2), na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(Model, Cause)

# ---------- Show summary table ----------
kable(cindex_summary_table, digits = 3,
      caption = "Cause-specific C-index with 95% Bootstrap CI")



# ================================================================
# 0️⃣ PBC Real Data
# ================================================================
library(JM)
library(survival)
library(dplyr)
library(tidyr)
library(keras)
library(tensorflow)
library(ggplot2)
library(MASS)
library(cmprsk)
library(survminer)
library(boot)

# ================================================================
# 1️⃣ Load & Prepare PBC dataset
# ================================================================
data(pbc2.id)

df <- pbc2.id %>%
  dplyr::select(id, years, status2,
                age, sex,
                serChol, albumin, SGOT, serBilir,
                spiders, ascites, hepatomegaly) %>%
  dplyr::mutate(
    sex = as.numeric(sex == "male"),
    spiders = as.numeric(spiders == "Yes"),
    ascites = as.numeric(ascites == "Yes"),
    hepatomegaly = as.numeric(hepatomegaly == "Yes"),
    event = status2,        # 0=censor, 1=death, 2=transplant
    time  = years
  ) %>%
  tidyr::drop_na()

covariates <- c("age","sex","serChol","albumin","SGOT","serBilir",
                "spiders","ascites","hepatomegaly")

# Train/test split
set.seed(123)
idx_train <- sample(seq_len(nrow(df)), floor(0.8*nrow(df)))
df_train <- df[idx_train, ]
df_test  <- df[-idx_train, ]

# Keras input arrays
X_train <- array(as.matrix(df_train[, covariates]), dim = c(nrow(df_train), 1, length(covariates)))
X_test  <- array(as.matrix(df_test[, covariates]), dim = c(nrow(df_test), 1, length(covariates)))

# One-hot competing-risk events
df_train$event1 <- ifelse(df_train$event == 1, 1, 0)
df_train$event2 <- ifelse(df_train$event == 2, 1, 0)
y_train_cr <- as.matrix(cbind(1 - (df_train$event1 + df_train$event2),
                              df_train$event1, df_train$event2))

df_test$event1 <- ifelse(df_test$event == 1, 1, 0)
df_test$event2 <- ifelse(df_test$event == 2, 1, 0)
y_test_cr <- as.matrix(cbind(1 - (df_test$event1 + df_test$event2),
                             df_test$event1, df_test$event2))

# ================================================================
# 2️⃣ Copula-loss functions
# ================================================================
to_uniform_tf <- function(x){
  u <- tf$math$sigmoid(tf$cast(x, tf$float32))
  tf$clip_by_value(u, 1e-6, 1-1e-6)
}

copula_gaussian_loss <- function(y_true, y_pred){
  rho <- tf$constant(0.5, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  z <- tf$sqrt(2) * tf$math$erfinv(2*u - 1)
  z1 <- z[,1]; z2 <- z[,2]
  detR <- 1 - rho^2
  invR <- 1 / detR
  quad <- invR * (z1^2 + z2^2 - 2*rho*z1*z2)
  loss_term <- -0.5*quad - 0.5*tf$math$log(detR)
  -tf$reduce_mean(loss_term)
}

copula_clayton_loss <- function(y_true, y_pred){
  theta <- tf$constant(1.5, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  S <- tf$reduce_sum(u^(-theta), axis=1L)
  log_c <- tf$math$log(1+theta) - (theta+1)*tf$reduce_sum(tf$math$log(u), axis=1L) - (2 + 1/theta)*tf$math$log(S - 1 + 1e-6)
  -tf$reduce_mean(log_c)
}

copula_gumbel_loss <- function(y_true, y_pred){
  theta <- tf$constant(2.0, dtype=tf$float32)
  u <- to_uniform_tf(y_pred)
  log_u <- -tf$math$log(u)
  phi <- log_u^theta
  S <- tf$reduce_sum(phi, axis=1L)
  log_C <- -S^(1/theta)
  log_c <- log_C +
    (1/theta - 1) * tf$math$log(S + 1e-6) +
    tf$reduce_sum((theta-1)*tf$math$log(log_u + 1e-6) - tf$math$log(u + 1e-6), axis=1L) +
    tf$math$log(1 + (theta-1)*S^(-1/theta))
  -tf$reduce_mean(log_c)
}

# ================================================================
# 3️⃣ CNN-LSTM model builder
# ================================================================
create_model <- function(loss_fn, n_features = length(covariates), n_causes = 2){
  inputs <- layer_input(shape = c(1, n_features))
  outputs <- inputs %>%
    layer_conv_1d(filters=16, kernel_size=1, activation="relu") %>%
    layer_lstm(16) %>%
    layer_dense(16, activation="relu") %>%
    layer_dense(n_causes, activation="sigmoid")
  
  model <- keras_model(inputs=inputs, outputs=outputs)
  model %>% compile(
    loss = loss_fn,
    optimizer = optimizer_adam(0.001)
  )
  return(model)
}

# ================================================================
# 4️⃣ Build and train models
# ================================================================
model_gauss <- create_model(copula_gaussian_loss)
model_clayton <- create_model(copula_clayton_loss)
model_gumbel <- create_model(copula_gumbel_loss)

model_gauss %>% fit(X_train, y_train_cr, epochs=10, batch_size=16, validation_split=0.2, verbose=1)
model_clayton %>% fit(X_train, y_train_cr, epochs=10, batch_size=16, validation_split=0.2, verbose=1)
model_gumbel %>% fit(X_train, y_train_cr, epochs=10, batch_size=16, validation_split=0.2, verbose=1)

pretrained_all <- list(
  copula_gauss = model_gauss,
  copula_clayton = model_clayton,
  copula_gumbel = model_gumbel
)

# ================================================================
# 5️⃣ Bootstrap C-index
# ================================================================
cindex_cause_boot_fn <- function(data, indices, model_name, cause=1){
  d <- data[indices, ]
  y_true <- d$event
  if(sum(y_true==cause)<2) return(NA)
  
  m <- pretrained_all[[model_name]]
  Xd <- array(as.matrix(d[,covariates]), dim=c(nrow(d),1,length(covariates)))
  p <- m %>% predict(Xd)
  score <- p[,cause]
  
  rcorr.cens(score, Surv(d$time, ifelse(y_true==cause,1,0)))["C Index"]
}

ci_safe <- function(b){ 
  if(all(is.na(b$t))||sd(b$t,na.rm=TRUE)==0) c(NA,NA) else boot.ci(b,type="perc")$percent[4:5] 
}

boot_models <- c("copula_gauss","copula_clayton","copula_gumbel")
boot_results_c1 <- lapply(boot_models, function(m) boot(df_test, function(d,i) cindex_cause_boot_fn(d,i,m,cause=1), R=50))
boot_results_c2 <- lapply(boot_models, function(m) boot(df_test, function(d,i) cindex_cause_boot_fn(d,i,m,cause=2), R=50))

summary_cindex <- data.frame(
  Model = c("Copula Gaussian","Copula Clayton","Copula Gumbel"),
  C_index_Cause1 = sapply(boot_results_c1,function(b) mean(b$t,na.rm=TRUE)),
  CI_lower_Cause1 = sapply(boot_results_c1,function(b) ci_safe(b)[1]),
  CI_upper_Cause1 = sapply(boot_results_c1,function(b) ci_safe(b)[2]),
  C_index_Cause2 = sapply(boot_results_c2,function(b) mean(b$t,na.rm=TRUE)),
  CI_lower_Cause2 = sapply(boot_results_c2,function(b) ci_safe(b)[1]),
  CI_upper_Cause2 = sapply(boot_results_c2,function(b) ci_safe(b)[2])
)

print(summary_cindex)

# ================================================================
# 6️⃣ Compute cause-specific CIFs for test set
# ================================================================
library(survival)
library(cmprsk)
library(ggplot2)
library(dplyr)

# Function to approximate discrete-time CIFs from model predictions
compute_cif <- function(model, X_data, max_time = 15, time_step = 0.25){
  # X_data: array of shape (n_samples,1,n_features)
  n <- dim(X_data)[1]
  times <- seq(0, max_time, by=time_step)
  n_times <- length(times)
  
  # Initialize matrices for CIFs
  cif1 <- matrix(0, nrow=n, ncol=n_times)
  cif2 <- matrix(0, nrow=n, ncol=n_times)
  surv_prob <- matrix(1, nrow=n, ncol=n_times)
  
  # Predict per-interval risks
  preds <- model %>% predict(X_data)
  # Ensure numeric & 2 causes
  if(ncol(preds) < 2) stop("Model prediction must have 2 causes")
  
  for(t in 1:n_times){
    # Discrete hazard approximation
    h1 <- preds[,1] * time_step
    h2 <- preds[,2] * time_step
    s_prev <- if(t==1) rep(1,n) else surv_prob[,t-1]
    
    cif1[,t] <- if(t==1) h1 else cif1[,t-1] + h1 * s_prev
    cif2[,t] <- if(t==1) h2 else cif2[,t-1] + h2 * s_prev
    surv_prob[,t] <- 1 - cif1[,t] - cif2[,t]
  }
  
  list(times = times, CIF1 = cif1, CIF2 = cif2)
}

# Compute CIFs for each model
cif_gauss   <- compute_cif(pretrained_all$copula_gauss, X_test)
cif_clayton <- compute_cif(pretrained_all$copula_clayton, X_test)
cif_gumbel  <- compute_cif(pretrained_all$copula_gumbel, X_test)

# ================================================================
# 7️⃣ Summarize and plot mean CIF curves
# ================================================================
mean_cif <- function(cif_obj){
  data.frame(
    time = cif_obj$times,
    CIF1 = colMeans(cif_obj$CIF1),
    CIF2 = colMeans(cif_obj$CIF2)
  )
}

df_cif_gauss   <- mean_cif(cif_gauss)   %>% mutate(Model="Copula Gaussian")
df_cif_clayton <- mean_cif(cif_clayton) %>% mutate(Model="Copula Clayton")
df_cif_gumbel  <- mean_cif(cif_gumbel)  %>% mutate(Model="Copula Gumbel")

df_plot <- bind_rows(df_cif_gauss, df_cif_clayton, df_cif_gumbel) %>%
  tidyr::pivot_longer(cols=c("CIF1","CIF2"), names_to="Cause", values_to="CIF")

# Plot mean CIF curves
ggplot(df_plot, aes(x=time, y=CIF, color=Model, linetype=Cause)) +
  geom_line(size=1) +
  theme_minimal() +
  labs(title="Predicted Cause-specific CIFs (PBC Test Set)",
       x="Time (years)",
       y="Cumulative incidence function",
       color="Model",
       linetype="Cause") +
  theme(axis.text=element_text(size=12),
        axis.title=element_text(size=13),
        legend.text=element_text(size=12),
        legend.title=element_text(size=13))

# ================================================================
# 8️⃣ Predicted CIF distributions
# ================================================================

# Function to create long-format CIF for all subjects at a given time
cif_long_format <- function(cif_obj, model_name, selected_time = 5){
  # selected_time: year at which to extract CIF
  time_idx <- which.min(abs(cif_obj$times - selected_time))
  
  data.frame(
    Subject = 1:nrow(cif_obj$CIF1),
    CIF1 = cif_obj$CIF1[,time_idx],
    CIF2 = cif_obj$CIF2[,time_idx],
    Model = model_name
  ) %>%
    tidyr::pivot_longer(cols = c("CIF1","CIF2"), names_to = "Cause", values_to = "CIF")
}

# Extract CIF distributions at 5 years
df_cif_gauss_dist   <- cif_long_format(cif_gauss, "Copula Gaussian", selected_time = 5)
df_cif_clayton_dist <- cif_long_format(cif_clayton, "Copula Clayton", selected_time = 5)
df_cif_gumbel_dist  <- cif_long_format(cif_gumbel, "Copula Gumbel", selected_time = 5)

df_cif_dist <- bind_rows(df_cif_gauss_dist,
                         df_cif_clayton_dist,
                         df_cif_gumbel_dist)

# ================================================================
# 8.1 Plot CIF distributions by model and cause
# ================================================================
ggplot(df_cif_dist, aes(x = CIF, fill = Model)) +
  geom_histogram(alpha = 0.5, position = "identity", bins = 20) +
  facet_wrap(~Cause) +
  theme_minimal() +
  labs(title = "Predicted CIF Distribution at 5 years (PBC Test Set)",
       x = "Cumulative Incidence Function",
       y = "Count",
       fill = "Model") +
  theme(axis.text = element_text(size=12),
        axis.title = element_text(size=13),
        legend.text = element_text(size=12),
        legend.title = element_text(size=13))
