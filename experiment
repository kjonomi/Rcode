rm(list = ls())


##############################################
## Gemini API Key USAGE R Code
# ==========================
# 1Ô∏è‚É£ Load libraries
# ==========================
library(data.table)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(kableExtra)
library(tensorflow)
library(keras)
# For Gemini API integration
library(gemini.R) 
library(jsonlite)
library(httr2)

# Check for API Key (essential for the LLM Policy)
#if (nchar(Sys.getenv("GEMINI_API_KEY")) < 5) {
#  warning("GEMINI_API_KEY not set. LLM Policy will return default values.")
#}

# ==========================
# 2Ô∏è‚É£ Simulate dataset
# ==========================
set.seed(123)
n <- 10000
num_features <- 20
cat_features <- 3

# Numeric features
sim_num <- replicate(num_features, {
  r <- runif(1)
  if(r < 0.33) rnorm(n, mean = runif(1, -2, 2), sd = runif(1, 0.5, 2))
  else if(r < 0.66) rgamma(n, shape = runif(1, 1, 3), scale = runif(1, 0.5, 2))
  else runif(n, -3, 3)
}, simplify = FALSE)
sim_num <- as.data.frame(sim_num)
colnames(sim_num) <- paste0("f", seq_len(num_features))

# Categorical features
sim_cat <- replicate(cat_features, sample(LETTERS[1:4], n, replace = TRUE), simplify = FALSE)
sim_cat <- as.data.frame(sim_cat)
colnames(sim_cat) <- paste0("c", seq_len(cat_features))

# Combine
criteo_sim <- as.data.table(bind_cols(sim_num, sim_cat))
criteo_sim[, id := seq_len(.N)]
setcolorder(criteo_sim, c("id", names(sim_num), names(sim_cat)))

# ==========================
# 3Ô∏è‚É£ Experimental design (2^K factorial + blocking)
# ==========================
K <- 5 # Number of treatments
basic_design <- expand.grid(replicate(K, c(0,1), simplify=FALSE)) %>%
  dplyr::rename_with(~paste0("treatment", seq_along(.)))

reps <- ceiling(n / nrow(basic_design))
design_long <- do.call("rbind", replicate(reps, basic_design, simplify = FALSE))
design_long <- design_long[1:n,]
rownames(design_long) <- NULL

# Blocking (using k-means on first 2 features)
num_cols <- names(criteo_sim)[grepl("^f", names(criteo_sim))][1:2]
X_dt <- criteo_sim[, ..num_cols]
for(j in seq_along(num_cols)) if(!is.numeric(X_dt[[j]])) X_dt[[j]] <- as.numeric(factor(X_dt[[j]]))
k_blocks <- 10
km <- kmeans(scale(as.matrix(X_dt)), centers = k_blocks, nstart = 20)
criteo_sim$block <- km$cluster

# Assign treatments within blocks
assigned_treats <- matrix(NA, nrow = n, ncol = K)
colnames(assigned_treats) <- paste0("treatment", 1:K)
for(b in sort(unique(criteo_sim$block))){
  ids_b <- which(criteo_sim$block == b)
  m <- length(ids_b)
  rows <- sample(1:nrow(basic_design), size = m, replace = TRUE)
  assigned_treats[ids_b, ] <- as.matrix(basic_design[rows, , drop=FALSE])
}
criteo_sim <- bind_cols(criteo_sim, as.data.frame(assigned_treats))


# ==========================
# 4Ô∏è‚É£ Balance diagnostics
# ==========================
criteo_sim$comb <- apply(criteo_sim[, paste0("treatment", 1:K), with = FALSE], 1, paste, collapse="")
cat("Treatment combination frequencies:\n")
print(table(criteo_sim$comb))

compute_smd <- function(df, group_var, covariates){
  smd_list <- lapply(covariates, function(var){
    vals <- df[[var]]
    if(!is.numeric(vals)) vals <- as.numeric(factor(vals))
    group_means <- tapply(vals, df[[group_var]], mean, na.rm=TRUE)
    group_sds <- tapply(vals, df[[group_var]], sd, na.rm=TRUE)
    pooled_sd <- sqrt(mean(group_sds^2, na.rm=TRUE))
    smd_vals <- (group_means - mean(vals, na.rm=TRUE)) / pooled_sd
    data.frame(Variable=var, Group=names(group_means), Mean=as.numeric(group_means), SMD_vs_Global=as.numeric(smd_vals))
  })
  do.call(rbind, smd_list)
}

num_covs <- names(criteo_sim)[grepl("^f", names(criteo_sim))][1:10]
smd_summary <- compute_smd(criteo_sim, "comb", num_covs)

ggplot(smd_summary, aes(x=Variable, y=SMD_vs_Global, color=Group)) +
  geom_point(size=2, alpha=0.7) +
  geom_hline(yintercept=c(-0.1,0.1), linetype="dashed", color="gray60") +
  theme_minimal(base_size=12) + coord_flip() +
  labs(title="Standardized Mean Differences by Treatment Combination",
       y="SMD vs Global Mean (|SMD| < 0.1 ‚âà balanced)",
       x="Feature")

# ==========================
# 5Ô∏è‚É£ Prepare data for CCDN
# ==========================
X_dt_full <- criteo_sim[, grepl("^f", names(criteo_sim)), with=FALSE]
for(j in seq_along(X_dt_full)) if(!is.numeric(X_dt_full[[j]])) X_dt_full[[j]] <- as.numeric(factor(X_dt_full[[j]]))
X <- scale(as.matrix(X_dt_full))
T_mat <- as.matrix(criteo_sim[, paste0("treatment", 1:K), with=FALSE])

# Simulate binary outcome
set.seed(456)
linear_part <- X[,1]*0.25 + X[,2]*(-0.15) + X[,3]*0.1
t_effect <- rowSums(T_mat) * 0.2
prob <- plogis(linear_part + t_effect + rnorm(n, 0, 0.5))
Y <- rbinom(n,1,prob)

# Subsample (CRITICAL for LLM policy speed/cost)
# Running on only 40 samples to prevent massive API usage!
idx <- sample(1:nrow(X), min(40, nrow(X))) 
X <- X[idx,]; T_mat <- T_mat[idx,]; Y <- Y[idx]

# Train/test split
set.seed(789)
train_idx <- sample(1:nrow(X), size=floor(0.8*nrow(X)))
X_train <- X[train_idx,]; T_train <- T_mat[train_idx,]; Y_train <- Y[train_idx]
X_test <- X[-train_idx,]; T_test <- T_mat[-train_idx,]; Y_test <- Y[-train_idx]
n_eval <- nrow(X_test)

# ==========================
# 6Ô∏è‚É£ Build CCDN model
# ==========================
input_dim <- ncol(X_train) + K
hidden_units <- 64

inputs <- layer_input(shape=input_dim)
x <- inputs %>% layer_dense(units=hidden_units, activation="relu") %>%
  layer_dense(units=hidden_units, activation="relu") %>%
  layer_dense(units=hidden_units, activation="relu")
outputs <- x %>% layer_dense(units=1, activation="sigmoid")
ccdn_model <- keras_model(inputs=inputs, outputs=outputs)

ccdn_model %>% compile(optimizer=optimizer_adam(0.001), loss="binary_crossentropy", metrics="accuracy")

train_input <- as.matrix(cbind(X_train, T_train))
test_input  <- as.matrix(cbind(X_test, T_test))
history <- ccdn_model %>% fit(train_input, Y_train, validation_data=list(test_input, Y_test), 
                              epochs=10, batch_size=64, verbose=0)
print(paste("CCDN Training Complete. Test Accuracy:", round(tail(history$metrics$val_accuracy, 1), 4)))


# ==============================================================
# 7Ô∏è‚É£ Define Policies (Greedy, Thompson, Gemini LLM)
# ==============================================================

all_combos <- as.matrix(expand.grid(replicate(K, c(0, 1), simplify = FALSE)))

# --- Greedy Policy (based on CCDN model) ---
greedy_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = K)
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    best_idx <- which.max(preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- Thompson Policy (based on CCDN model) ---
thompson_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = K)
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    mean_preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    # Sample from a normal distribution around the mean prediction
    sampled_preds <- pmin(pmax(rnorm(length(mean_preds), mean = mean_preds, sd = 0.05), 0), 1)
    best_idx <- which.max(sampled_preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- üéØ Gemini LLM Policy (Actual API Call) ---

# Define the structured output schema for the probability (as an R list)
PROBABILITY_SCHEMA <- list(
  type = "OBJECT",
  properties = list(
    PredictedProbability = list(
      type = "NUMBER",
      description = "The predicted conversion probability between 0 and 1, rounded to 4 decimal places."
    )
  ),
  required = c("PredictedProbability")
)

actual_llm_predict_reward <- function(context_features, treatment_vec, model_id = "gemini-2.5-flash") {
  
  if (nchar(Sys.getenv("GEMINI_API_KEY")) < 5) return(0.5) # Fail-safe if key is missing
  
  # 1. Format numerical inputs into a text prompt
  X_str <- paste0("F", 1:length(context_features), "=", round(context_features, 3), collapse=", ")
  T_str <- paste0("T", 1:length(treatment_vec), "=", treatment_vec, collapse=", ")
  
  prompt <- paste0(
    "Act as an expert personalized treatment model. ",
    "Given the following scaled user features and the binary treatment vector, ",
    "predict the conversion probability (a decimal between 0 and 1). ",
    "Features: ", X_str, ". ",
    "Treatment: ", T_str, "."
  )
  
  # 2. Call the Gemini API requesting a structured JSON output
  response <- tryCatch({
    # Use gemini_structured from the gemini.R package
    gemini_structured(
      prompt = prompt,
      schema = PROBABILITY_SCHEMA,
      model_id = model_id,
      temperature = 0, # Low temperature for deterministic output
      timeout = 60
    )
  }, error = function(e) {
    warning(paste("Gemini API call failed:", e$message, "Returning 0.5."))
    return(NULL) 
  })
  
  # 3. Parse the JSON response
  if (!is.null(response) && !is.null(response$PredictedProbability)) {
    return(as.numeric(response$PredictedProbability))
  } else {
    return(0.5) # Fail-safe 
  }
}


llm_policy <- function(X, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = K)
  
  print(paste("Executing Gemini LLM Policy on", n, "samples. This will make", n * K_combos, "API calls and take time."))
  
  for (i in 1:n) {
    
    # Apply the actual API call function to each treatment combination
    combo_preds <- apply(all_combos, 1, function(t_vec)
      actual_llm_predict_reward(X[i, ], t_vec))
    
    # Select the treatment with the highest predicted reward
    best_idx <- which.max(combo_preds)
    selected[i, ] <- all_combos[best_idx, ]
    
    # Add a small pause to prevent hitting API rate limits
    Sys.sleep(0.1) 
  }
  selected
}

# ==============================================================
# 8Ô∏è‚É£ Apply All Policies
# ==============================================================

X_eval <- X_test

policy_list <- list(
  Greedy    = greedy_policy(X_eval, ccdn_model, all_combos),
  Thompson  = thompson_policy(X_eval, ccdn_model, all_combos),
  LLM       = llm_policy(X_eval, all_combos)
)

# ==============================================================
# 9Ô∏è‚É£ Evaluate Empirical Outcomes and MRO
# ==============================================================

library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)

# --- Part A: Define Model-Relative Optimal (MRO) ---
# MRO is the theoretical ceiling according to the CCDN's internal logic.
# This represents the "Gold Standard" the agent *could* achieve if it searched perfectly.

mro_data <- lapply(1:nrow(X_eval), function(i) {
  # Batch predict all combinations for this specific context to find the local maxima
  context_rep <- matrix(rep(as.numeric(X_eval[i, ]), each = nrow(all_combos)), 
                        nrow = nrow(all_combos), byrow = TRUE)
  inp <- cbind(context_rep, all_combos)
  preds <- as.numeric(ccdn_model %>% predict(inp, verbose = 0))
  
  return(data.frame(mro_val = max(preds), mro_idx = which.max(preds)))
})

mro_results <- bind_rows(mro_data)

# --- Part B: Evaluate Empirical Rewards for Policies ---
# Evaluate outcomes across the test set using the CCDN as the reward surrogate.

evaluate_policy <- function(policy_matrix, model, context_matrix) {
  # Prepare input: [Context | Action]
  inp <- cbind(context_matrix, policy_matrix)
  as.numeric(model %>% predict(inp, verbose = 0))
}

# Calculate rewards for all policies in the list
policy_rewards <- lapply(policy_list, function(p) evaluate_policy(p, ccdn_model, X_eval))

# Combine into a clean dataframe
reward_df <- as.data.frame(policy_rewards)
colnames(reward_df) <- names(policy_list)

# --- Part C: Visualization and Statistical Testing ---

# Reshape for ggplot
policy_long <- reward_df %>%
  mutate(id = 1:n(), MRO = mro_results$mro_val) %>%
  pivot_longer(cols = -c(id, MRO), names_to = "Policy", values_to = "Outcome")

# Plot: Outcome with Significance 
# We compare the distribution of outcomes against the LLM baseline
ggplot(policy_long, aes(x = Policy, y = Outcome, fill = Policy)) +
  geom_boxplot(alpha = 0.6, outlier.shape = NA) + 
  geom_jitter(width = 0.1, alpha = 0.1, size = 0.5) +
  # Add the MRO as a dashed reference line representing the theoretical limit
  geom_hline(aes(yintercept = mean(MRO)), linetype = "dashed", color = "red", alpha = 0.7) +
  stat_compare_means(method = "wilcox.test", 
                     label = "p.signif", 
                     ref.group = "LLM",
                     label.y = max(policy_long$Outcome) * 1.05) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Policy Performance vs. LLM Baseline",
    subtitle = "Red line indicates mean MRO (Model-Relative Optimal)",
    y = "Empirical Outcome (P(Y=1))",
    x = "Decision Policy"
  ) +
  theme(legend.position = "none")


# ==============================================================
# üîü Regret and Coverage Evaluation (MRO-centric)
# ==============================================================

# Regret: MRO value (theoretical max) minus Policy selection value
# Using the pre-calculated mro_results from Section 9
regret_list <- lapply(reward_df, function(p_val) mro_results$mro_val - p_val)

regret_df <- as.data.frame(regret_list) %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Regret")

# Coverage: Does selected treatment match MRO treatment?
# Measuring how often the policy hits the model-optimal action
coverage_list <- lapply(names(policy_list), function(pol_name) {
  sel <- policy_list[[pol_name]]
  sapply(1:nrow(sel), function(i) {
    # Compare selected vector to the specific action vector identified as MRO
    identical(as.numeric(sel[i, ]), as.numeric(all_combos[mro_results$mro_idx[i], ]))
  })
})
names(coverage_list) <- names(policy_list)

coverage_df <- as.data.frame(coverage_list) %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Coverage")

# ==============================================================
# 1Ô∏è‚É£1Ô∏è‚É£ Visualization (Improved Readability)
# ==============================================================

# Plot 1: Regret with Significance Tests
p1 <- ggplot(regret_df, aes(x = Policy, y = Regret, fill = Policy)) +
  geom_boxplot(alpha = 0.7, outlier.size = 0.5) +
  stat_compare_means(label = "p.signif", method = "wilcox.test", ref.group = "LLM") +
  theme_bw(base_size = 14) +
  labs(title = "MRO Regret Comparison", 
       subtitle = "Wilcoxon test against LLM baseline",
       y = "Regret (MRO Value - Policy Value)") +
  theme(legend.position = "none")

# Plot 2: MRO Coverage (Match Rate)
coverage_summary <- coverage_df %>%
  group_by(Policy) %>%
  summarise(Mean = mean(Coverage), 
            SE = sd(Coverage)/sqrt(n())) # Standard Error for error bars

p2 <- ggplot(coverage_summary, aes(x = Policy, y = Mean, fill = Policy)) +
  geom_bar(stat = "identity", width = 0.6, alpha = 0.8) +
  geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), width = 0.2) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  theme_bw(base_size = 14) +
  labs(title = "MRO Coverage Rate", 
       subtitle = "Accuracy relative to model-optimal action",
       y = "% Match with MRO Action") +
  theme(legend.position = "none")

print(p1)
print(p2)
# ==============================================================
# 1Ô∏è‚É£2Ô∏è‚É£ Summary Tables (Reporting CI/SD and N)
# ==============================================================

# Create Consolidated Table with separate columns for Mean and SD
# Decoupling metrics for statistical clarity
summary_table <- regret_df %>%
  group_by(Policy) %>%
  summarise(
    N = n(),
    # Outcome Metrics
    Mean_Outcome = mean(reward_df[[unique(Policy)]]),
    SD_Outcome   = sd(reward_df[[unique(Policy)]]),
    # Regret Metrics (MRO - Actual)
    Mean_Regret  = mean(Regret),
    SD_Regret    = sd(Regret),
    # Coverage Metric (Match rate with MRO action)
    MRO_Coverage = mean(coverage_df$Coverage[coverage_df$Policy == unique(Policy)])
  ) %>%
  # Round all numeric values to 4 decimal places for publication readiness
  mutate(across(where(is.numeric), ~round(., 4)))

# Render table with knitr
# Using align = "lrrrrr" to ensure numbers are right-aligned for readability
print(knitr::kable(
  summary_table, 
  col.names = c("Policy", "N", "Mean Outcome", "SD Outcome", "Mean Regret", "SD Regret", "MRO Coverage"),
  caption = "Table 1: Policy Performance Summary (100 Seeds, B=6)"
))


# ==============================================================================
# Full R Code: Boston Housing CCDN Simulation with Blocking and Multi-Policy Evaluation
# ==============================================================================

# 0Ô∏è‚É£ Library Setup (UPDATED)
# ==============================================================================
library(data.table)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(kableExtra)
library(tensorflow)
library(keras)
library(MASS)
# --- New Libraries for Gemini API ---
library(gemini.R) 
library(jsonlite)
library(httr2)

set.seed(123)



# 1Ô∏è‚É£ Load Boston Dataset
# ==============================================================================
data("Boston", package = "MASS")
boston <- as.data.table(Boston)

# Binary outcome: expensive house if medv >= median
Y_full <- as.numeric(boston$medv >= median(boston$medv))
boston[, medv := NULL]

# Standardize all numeric covariates
X_mat <- scale(as.matrix(boston))
feature_cols <- colnames(X_mat)
n <- nrow(X_mat)

# 2Ô∏è‚É£ Factorial Design and Blocking
# ==============================================================================
K <- 5  # number of binary treatments
basic_design <- expand.grid(replicate(K, c(0, 1), simplify = FALSE)) %>%
  rename_with(~ paste0("treatment", seq_along(.)))

# Blocking using first two covariates
k_blocks <- 10
block_input <- scale(as.matrix(X_mat[, 1:2]))
km <- kmeans(block_input, centers = k_blocks, nstart = 20)
blocks <- km$cluster

# Assign treatments within blocks
assigned_treats <- matrix(NA, nrow = n, ncol = K)
colnames(assigned_treats) <- paste0("treatment", 1:K)
for (b in sort(unique(blocks))) {
  ids_b <- which(blocks == b)
  m <- length(ids_b)
  rows <- sample(1:nrow(basic_design), size = m, replace = TRUE)
  assigned_treats[ids_b, ] <- as.matrix(basic_design[rows, , drop = FALSE])
}

# Combine into main dataset
boston_sim <- as.data.table(boston)
boston_sim[, id := seq_len(.N)]
boston_sim[, block := blocks]
boston_sim <- bind_cols(boston_sim, as.data.frame(assigned_treats))
boston_sim[, outcome := Y_full]

# 3Ô∏è‚É£ Balance Diagnostics
# ==============================================================================
boston_sim$comb <- apply(boston_sim[, paste0("treatment", 1:K), with = FALSE],
                         1, paste, collapse = "")

cat("Treatment combination frequencies:\n")
print(table(boston_sim$comb))

compute_smd <- function(df, group_var, covariates) {
  smd_list <- lapply(covariates, function(var) {
    vals <- df[[var]]
    group_means <- tapply(vals, df[[group_var]], mean, na.rm = TRUE)
    group_sds <- tapply(vals, df[[group_var]], sd, na.rm = TRUE)
    pooled_sd <- sqrt(mean(group_sds^2, na.rm = TRUE))
    smd_vals <- (group_means - mean(vals, na.rm = TRUE)) / pooled_sd
    data.frame(Variable = var, Group = names(group_means),
               Mean = as.numeric(group_means),
               SMD_vs_Global = as.numeric(smd_vals))
  })
  do.call(rbind, smd_list)
}

smd_summary <- compute_smd(boston_sim, "comb", feature_cols)

ggplot(smd_summary, aes(x = Variable, y = SMD_vs_Global, color = Group)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_hline(yintercept = c(-0.1, 0.1), linetype = "dashed", color = "gray60") +
  theme_minimal(base_size = 12) + coord_flip() +
  labs(title = "Standardized Mean Differences by Treatment Combination",
       y = "SMD vs Global Mean (|SMD| < 0.1 ‚âà balanced)", x = "Feature")

# 4Ô∏è‚É£ Prepare Data for CCDN
# ==============================================================================
T_mat <- as.matrix(boston_sim[, paste0("treatment", 1:K), with = FALSE])
X <- X_mat
Y <- boston_sim$outcome

set.seed(456)
idx <- sample(1:nrow(X), min(2000, nrow(X)))
X <- X[idx,]; T_mat <- T_mat[idx,]; Y <- Y[idx]

set.seed(789)
train_idx <- sample(1:nrow(X), size = floor(0.8 * nrow(X)))
X_train <- X[train_idx,]; T_train <- T_mat[train_idx,]; Y_train <- Y[train_idx]
X_test  <- X[-train_idx,]; T_test  <- T_mat[-train_idx,]; Y_test  <- Y[-train_idx]



# 4Ô∏è‚É£ Prepare Data for CCDN
# ==============================================================================
T_mat <- as.matrix(boston_sim[, paste0("treatment", 1:K), with = FALSE])
X <- X_mat
Y <- boston_sim$outcome

# CRITICAL SUBSAMPLING FOR LLM API (Reduced from 2000 to 100 for safety)
set.seed(456)
idx <- sample(1:nrow(X), min(100, nrow(X))) 
X <- X[idx,]; T_mat <- T_mat[idx,]; Y <- Y[idx]

set.seed(789)
train_idx <- sample(1:nrow(X), size = floor(0.8 * nrow(X)))
X_train <- X[train_idx,]; T_train <- T_mat[train_idx,]; Y_train <- Y[train_idx]
X_test  <- X[-train_idx,]; T_test  <- T_mat[-train_idx,]; Y_test  <- Y[-train_idx]

# 5Ô∏è‚É£ CCDN Model (Keras)
# ==============================================================================
input_dim <- ncol(X_train) + K
hidden_units <- 64

inputs <- layer_input(shape = input_dim)
x <- inputs %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu")
outputs <- x %>% layer_dense(units = 1, activation = "sigmoid")
ccdn_model <- keras_model(inputs = inputs, outputs = outputs)

ccdn_model %>% compile(
  optimizer = optimizer_adam(0.001),
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

train_input <- as.matrix(cbind(X_train, T_train))
test_input  <- as.matrix(cbind(X_test, T_test))

history <- ccdn_model %>% fit(
  train_input, Y_train,
  validation_data = list(test_input, Y_test),
  epochs = 10, batch_size = 64, verbose = 0
)

# ==============================================================
# 6Ô∏è‚É£ Define Policies (Greedy, Thompson, Gemini LLM) (UPDATED)
# ==============================================================

all_combos <- as.matrix(expand.grid(replicate(K, c(0, 1), simplify = FALSE)))

# --- Greedy Policy (remains the same) ---
greedy_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    best_idx <- which.max(preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- Thompson Policy (remains the same) ---
thompson_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    mean_preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    sampled_preds <- pmin(pmax(rnorm(length(mean_preds), mean = mean_preds, sd = 0.05), 0), 1)
    best_idx <- which.max(sampled_preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- üéØ Gemini LLM Policy (Actual API Call) ---

PROBABILITY_SCHEMA <- list(
  type = "OBJECT",
  properties = list(
    PredictedProbability = list(
      type = "NUMBER",
      description = "The predicted conversion probability between 0 and 1, rounded to 4 decimal places."
    )
  ),
  required = c("PredictedProbability")
)

actual_llm_predict_reward <- function(context_features, treatment_vec, model_id = "gemini-2.5-flash") {
  
  if (nchar(Sys.getenv("GEMINI_API_KEY")) < 5) return(0.5)
  
  X_str <- paste0(feature_cols, "=", round(context_features, 3), collapse=", ")
  T_str <- paste0("T", 1:length(treatment_vec), "=", treatment_vec, collapse=", ")
  
  prompt <- paste0(
    "Act as an expert housing market policy evaluator. ",
    "Given the standardized Boston Housing features and the binary treatment vector, ",
    "predict the probability (a decimal between 0 and 1) that the house is 'expensive' (medv >= median). ",
    "Features: ", X_str, ". ",
    "Treatment: ", T_str, "."
  )
  
  response <- tryCatch({
    gemini_structured(
      prompt = prompt,
      schema = PROBABILITY_SCHEMA,
      model_id = model_id,
      temperature = 0,
      timeout = 30
    )
  }, error = function(e) {
    warning(paste("Gemini API call failed:", e$message, "Returning 0.5."))
    return(NULL) 
  })
  
  if (!is.null(response) && !is.null(response$PredictedProbability)) {
    return(as.numeric(response$PredictedProbability))
  } else {
    return(0.5) 
  }
}

llm_policy <- function(X, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  
  print(paste("Executing Gemini LLM Policy on", n, "samples. Total API calls:", n * K_combos))
  
  for (i in 1:n) {
    combo_preds <- apply(all_combos, 1, function(t_vec)
      actual_llm_predict_reward(X[i, ], t_vec))
    
    best_idx <- which.max(combo_preds)
    selected[i, ] <- all_combos[best_idx, ]
    
    Sys.sleep(0.2) 
  }
  selected
}

# ==============================================================
# 7Ô∏è‚É£ Apply All Policies (No UCB, No Random)
# ==============================================================

X_eval <- X_test
n_eval <- nrow(X_eval)

policy_list <- list(
  Greedy    = greedy_policy(X_eval, ccdn_model, all_combos),
  Thompson  = thompson_policy(X_eval, ccdn_model, all_combos),
  LLM       = llm_policy(X_eval, all_combos)
)

# ==============================================================
# 8Ô∏è‚É£ Evaluate Outcomes (Standardized Mean ¬± SD)
# ==============================================================
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr) # Required for statistical significance brackets

# Evaluate empirical rewards for each policy
# Ensure metrics are calculated over test set n and seeds
policy_preds <- lapply(policy_list, function(sel) {
  # Vectorized prediction approach to improve speed over apply()
  sapply(1:nrow(sel), function(i) {
    inp <- matrix(c(as.numeric(X_eval[i, ]), as.numeric(sel[i, ])), nrow = 1)
    as.numeric(ccdn_model %>% predict(inp, verbose = 0))
  })
})

policy_df <- as.data.frame(policy_preds)
colnames(policy_df) <- names(policy_list)

# Reshape for ggplot
policy_long <- policy_df %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "EmpiricalOutcome")

# Plot 1: Outcome with Significance 
ggplot(policy_long, aes(x = Policy, y = EmpiricalOutcome, fill = Policy)) +
  geom_boxplot(alpha = 0.7, outlier.size = 0.5) +
  stat_compare_means(method = "wilcox.test", label = "p.signif", ref.group = "LLM") +
  theme_bw(base_size = 14) +
  labs(title = "Empirical Outcome Comparison (Boston Housing)", 
       subtitle = "Wilcoxon test against LLM baseline",
       y = "Predicted Probability (Y=1)")

# ==============================================================
# 9Ô∏è‚É£ MRO Regret and Coverage 
# ==============================================================
# Efficiently find the MRO index and value
mro_results <- apply(X_eval, 1, function(x_row) {
  # Create a matrix of all possible treatments for this specific context
  all_treats_matrix <- as.matrix(all_combos)
  context_matrix <- matrix(rep(x_row, each = nrow(all_treats_matrix)), 
                           nrow = nrow(all_treats_matrix), byrow = TRUE)
  inp <- cbind(context_matrix, all_treats_matrix)
  
  preds <- as.numeric(ccdn_model %>% predict(inp, verbose = 0))
  return(c(value = max(preds), idx = which.max(preds)))
})

mro_vals <- mro_results["value", ]
mro_indices <- mro_results["idx", ]

# Regret computation (MRO Value - Policy Value)
regret_list <- lapply(policy_preds, function(preds) mro_vals - preds)
regret_df <- as.data.frame(regret_list) %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Regret")

# Plot 2: Regret 
ggplot(regret_df, aes(x = Policy, y = Regret, fill = Policy)) +
  geom_boxplot(alpha = 0.8) +
  theme_bw(base_size = 14) +
  labs(title = "Policy Regret Comparison (Boston Housing)", 
       subtitle = "Relative to Model-Relative Optimal (MRO)",
       y = "Regret (MRO Max - Policy Prediction)")


# Coverage computation (Match with MRO action)
policy_coverage <- sapply(names(policy_list), function(p_name) {
  sel <- policy_list[[p_name]]
  correct <- sapply(1:nrow(sel), function(i) {
    # Check if selected treatment vector matches the MRO treatment vector
    identical(as.numeric(sel[i, ]), as.numeric(all_combos[mro_indices[i], ]))
  })
  mean(correct)
})

coverage_df <- data.frame(Policy = names(policy_coverage), Coverage = policy_coverage)

# Plot 3: Coverage bar chart
ggplot(coverage_df, aes(x = Policy, y = Coverage, fill = Policy)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(Coverage, 3)), vpos = -0.5) +
  ylim(0, 1.1) +
  theme_minimal(base_size = 14) +
  labs(title = "MRO Coverage Rate", y = "Fraction of Optimal Actions Selected")

# ==============================================================
# SUMMARY TABLES (Mean ¬± SD and N included)
# ==============================================================
# Explicitly stating sample size and variability

# Table 1: Detailed Policy Metrics
summary_stats <- policy_long %>%
  group_by(Policy) %>%
  summarise(
    n = n(),
    Mean_Outcome = mean(EmpiricalOutcome),
    SD_Outcome = sd(EmpiricalOutcome),
    Mean_Regret = mean(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    SD_Regret = sd(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    MRO_Coverage = coverage_df$Coverage[coverage_df$Policy == unique(Policy)]
  ) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

knitr::kable(summary_stats, caption = "Table 1: Policy Performance Summary (Mean ¬± SD)")

# ==============================================================================
# CCDN Simulation on Wine Quality Dataset (UPDATED for Gemini LLM)
# ==============================================================================

library(data.table)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(kableExtra)
library(tensorflow)
library(keras)
# --- New Libraries for Gemini API ---
library(gemini.R) 
library(jsonlite)
library(httr2)

set.seed(123)


# ==========================
# 1Ô∏è‚É£ Load Wine Quality dataset
# ==========================
# Use google tool to fetch the file path if necessary, but assuming local file for simplicity
wine <- fread("winequality-red.csv", sep = ";")
#wine <- fread(paste0("https://archive.ics.uci.edu/ml/machine-learning-databases/",
#                    "wine-quality/winequality-red.csv"), sep = ";")

# Define outcome and covariates
Y_full <- as.numeric(wine$quality >= 6)  # binary: good wine (‚â•6)
wine <- dplyr::select(wine, -quality)

feature_cols <- names(wine)

# Standardize
X_mat <- scale(as.matrix(wine))

# ==========================
# 2Ô∏è‚É£ Experimental design (2^4 factorial + blocking)
# ==========================
K <- 5
basic_design <- expand.grid(replicate(K, c(0,1), simplify=FALSE)) %>%
  dplyr::rename_with(~paste0("treatment", seq_along(.)))

n <- nrow(X_mat)

# Blocking using first two covariates
k_blocks <- 10
block_input <- scale(as.matrix(X_mat[, 1:2]))
km <- kmeans(block_input, centers = k_blocks, nstart = 20)
blocks <- km$cluster

# Assign treatments within blocks
assigned_treats <- matrix(NA, nrow = n, ncol = K)
colnames(assigned_treats) <- paste0("treatment", 1:K)
for(b in sort(unique(blocks))){
  ids_b <- which(blocks == b)
  m <- length(ids_b)
  rows <- sample(1:nrow(basic_design), size = m, replace = TRUE)
  assigned_treats[ids_b, ] <- as.matrix(basic_design[rows, , drop=FALSE])
}

wine_sim <- as.data.table(wine)

# Add id and block
wine_sim[, id := .I]
wine_sim[, block := blocks]

# Add treatments (assigned_treats) by reference
for(j in seq_len(K)){
  wine_sim[, paste0("treatment", j) := assigned_treats[, j]]
}

# Add outcome
wine_sim[, outcome := Y_full]


# ==========================
# 3Ô∏è‚É£ Balance diagnostics (unchanged)
# ==========================
wine_sim$comb <- apply(as.matrix(wine_sim[, paste0("treatment", 1:K), with = FALSE]), 1, paste, collapse = "")
cat("Treatment combination frequencies:\n")
print(table(wine_sim$comb))

compute_smd <- function(df, group_var, covariates){
  smd_list <- lapply(covariates, function(var){
    vals <- df[[var]]
    group_means <- tapply(vals, df[[group_var]], mean, na.rm=TRUE)
    group_sds <- tapply(vals, df[[group_var]], sd, na.rm=TRUE)
    pooled_sd <- sqrt(mean(group_sds^2, na.rm=TRUE))
    smd_vals <- (group_means - mean(vals, na.rm=TRUE)) / pooled_sd
    data.frame(Variable=var, Group=names(group_means), Mean=as.numeric(group_means), SMD_vs_Global=as.numeric(smd_vals))
  })
  do.call(rbind, smd_list)
}

smd_summary <- compute_smd(wine_sim, "comb", feature_cols)

ggplot(smd_summary, aes(x=Variable, y=SMD_vs_Global, color=Group)) +
  geom_point(size=2, alpha=0.7) +
  geom_hline(yintercept=c(-0.1,0.1), linetype="dashed", color="gray60") +
  theme_minimal(base_size=12) + coord_flip() +
  labs(title="Standardized Mean Differences by Treatment Combination",
       y="SMD vs Global Mean (|SMD| < 0.1 ‚âà balanced)", x="Feature")

# ==========================
# 4Ô∏è‚É£ Prepare data for CCDN (CRITICAL SUBSAMPLING ADJUSTMENT)
# ==========================
T_mat <- as.matrix(wine_sim[, paste0("treatment", 1:K), with = FALSE])
X <- X_mat
Y <- wine_sim$outcome

# CRITICAL SUBSAMPLING: Reduced size for safe LLM API testing
set.seed(456)
idx <- sample(1:nrow(X), min(50, nrow(X))) 
X <- X[idx,]; T_mat <- T_mat[idx,]; Y <- Y[idx]

set.seed(789)
train_idx <- sample(1:nrow(X), size = floor(0.8 * nrow(X)))
X_train <- X[train_idx,]; T_train <- T_mat[train_idx,]; Y_train <- Y[train_idx]
X_test  <- X[-train_idx,]; T_test  <- T_mat[-train_idx,]; Y_test  <- Y[-train_idx]
n_eval <- nrow(X_test)

# ==========================
# 5Ô∏è‚É£ CCDN model (Keras)
# ==========================
input_dim <- ncol(X_train) + K
hidden_units <- 64

inputs <- layer_input(shape = input_dim)
x <- inputs %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu")
outputs <- x %>% layer_dense(units = 1, activation = "sigmoid")
ccdn_model <- keras_model(inputs = inputs, outputs = outputs)

ccdn_model %>% compile(
  optimizer = optimizer_adam(0.001),
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

train_input <- as.matrix(cbind(X_train, T_train))
test_input  <- as.matrix(cbind(X_test, T_test))

history <- ccdn_model %>% fit(
  train_input, Y_train,
  validation_data = list(test_input, Y_test),
  epochs = 10, batch_size = 64, verbose = 0
)


# ==============================================================
# 6Ô∏è‚É£ Define Policies (Greedy, Thompson, Gemini LLM) (UPDATED)
# ==============================================================

all_combos <- as.matrix(expand.grid(replicate(K, c(0, 1), simplify = FALSE)))

# --- Greedy Policy (unchanged) ---
greedy_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    best_idx <- which.max(preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- Thompson Policy (unchanged) ---
thompson_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    mean_preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    sampled_preds <- pmin(pmax(rnorm(length(mean_preds), mean = mean_preds, sd = 0.05), 0), 1)
    best_idx <- which.max(sampled_preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- üéØ Gemini LLM Policy (Actual API Call) ---

PROBABILITY_SCHEMA <- list(
  type = "OBJECT",
  properties = list(
    PredictedProbability = list(
      type = "NUMBER",
      description = "The predicted probability of the wine being good (quality >= 6), between 0 and 1, rounded to 4 decimal places."
    )
  ),
  required = c("PredictedProbability")
)

actual_llm_predict_reward <- function(context_features, treatment_vec, model_id = "gemini-2.5-flash") {
  
  if (nchar(Sys.getenv("GEMINI_API_KEY")) < 5) return(0.5)
  
  X_str <- paste0(feature_cols, "=", round(context_features, 3), collapse=", ")
  T_str <- paste0("T", 1:length(treatment_vec), "=", treatment_vec, collapse=", ")
  
  prompt <- paste0(
    "Act as an expert sommelier and predictive model. ",
    "Given the standardized chemical features of a red wine and the binary treatments applied, ",
    "predict the probability (a decimal between 0 and 1) that the wine receives a 'good' quality score (>= 6). ",
    "Features: ", X_str, ". ",
    "Treatments: ", T_str, "."
  )
  
  response <- tryCatch({
    gemini_structured(
      prompt = prompt,
      schema = PROBABILITY_SCHEMA,
      model_id = model_id,
      temperature = 0,
      timeout = 30 
    )
  }, error = function(e) {
    warning(paste("Gemini API call failed:", e$message, "Returning 0.5."))
    return(NULL) 
  })
  
  if (!is.null(response) && !is.null(response$PredictedProbability)) {
    return(as.numeric(response$PredictedProbability))
  } else {
    return(0.5) 
  }
}

llm_policy <- function(X, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  
  print(paste("Executing Gemini LLM Policy on", n, "samples. Total API calls:", n * K_combos))
  
  for (i in 1:n) {
    combo_preds <- apply(all_combos, 1, function(t_vec)
      actual_llm_predict_reward(X[i, ], t_vec))
    
    best_idx <- which.max(combo_preds)
    selected[i, ] <- all_combos[best_idx, ]
    
    Sys.sleep(0.2) 
  }
  selected
}


# ==============================================================
# 7Ô∏è‚É£ Apply All Policies (No UCB, No Random)
# ==============================================================

X_eval <- X_test

policy_list <- list(
  Greedy    = greedy_policy(X_eval, ccdn_model, all_combos),
  Thompson  = thompson_policy(X_eval, ccdn_model, all_combos),
  LLM       = llm_policy(X_eval, all_combos)
)
# ==============================================================
# 8Ô∏è‚É£ Evaluate Outcomes (Standardized Mean ¬± SD)
# ==============================================================
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr) # Required for statistical significance brackets

# Define n_eval based on the actual evaluation set size
n_eval <- nrow(X_eval)

# Batch prediction helper to improve efficiency (Transparency)
# Instead of one-by-one, we batch predict to save overhead
get_preds <- function(features, actions) {
  inp <- as.matrix(cbind(features, actions))
  as.numeric(ccdn_model %>% predict(inp, verbose = 0))
}

policy_preds <- lapply(policy_list, function(sel) {
  get_preds(X_eval, sel)
})

policy_df <- as.data.frame(policy_preds)
colnames(policy_df) <- names(policy_list)

# Reshape for ggplot
policy_long <- policy_df %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Outcome")

# Plot 1: Empirical Outcome with Significance
ggplot(policy_long, aes(x = Policy, y = Outcome, fill = Policy)) +
  geom_boxplot(alpha = 0.7, outlier.size = 0.5) +
  stat_compare_means(method = "wilcox.test", label = "p.signif", ref.group = "LLM") +
  theme_bw(base_size = 14) +
  labs(title = "Policy Empirical Outcomes (Wine Quality)", 
       subtitle = "Wilcoxon test against LLM baseline",
       y = "Predicted Probability (Y=1)")

# ==============================================================
# 9Ô∏è‚É£ MRO Regret and Coverage (Revised Terminology)
# ==============================================================
# The MRO is the best the model can do given its current state.

# Pre-calculate MRO for all individuals efficiently
mro_data <- apply(X_eval, 1, function(x_row) {
  # Repeat the individual context for all possible factorial combinations (16)
  context_rep <- matrix(rep(x_row, each = nrow(all_combos)), nrow = nrow(all_combos))
  preds <- get_preds(context_rep, all_combos)
  
  return(c(val = max(preds), idx = which.max(preds)))
})

mro_vals <- mro_data["val", ]
mro_indices <- mro_data["idx", ]

# Regret: MRO Value minus Policy Selection Value
regret_list <- lapply(policy_preds, function(preds) mro_vals - preds)

regret_df <- as.data.frame(regret_list) %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Regret")

# Coverage: Does policy action == MRO action?
policy_coverage <- sapply(names(policy_list), function(p_name) {
  sel_actions <- policy_list[[p_name]]
  matches <- sapply(1:n_eval, function(i) {
    # Check if selected treatment vector matches the MRO treatment vector
    identical(as.numeric(sel_actions[i, ]), as.numeric(all_combos[mro_indices[i], ]))
  })
  mean(matches)
})

policy_coverage_df <- data.frame(Policy = names(policy_coverage), Coverage = policy_coverage)

# Plot 2: Regret with MRO labels
ggplot(regret_df, aes(x = Policy, y = Regret, fill = Policy)) +
  geom_boxplot(alpha = 0.8) +
  theme_bw(base_size = 14) +
  labs(title = "Policy Regret Comparison (Wine Quality)", 
       subtitle = "Relative to Model-Relative Optimal (MRO)",
       y = "Regret (MRO Max - Policy Prediction)")

# Plot 3: Coverage (Fraction of MRO Matches)
ggplot(policy_coverage_df, aes(x = Policy, y = Coverage, fill = Policy)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(Coverage, 3)), vpos = -0.5) +
  ylim(0, 1.1) +
  theme_minimal(base_size = 14) +
  labs(title = "MRO Coverage Rate", y = "Coverage", x = "Policy")

# ==============================================================
# üîü CONSOLIDATED SUMMARY TABLE (Reporting N & SD)
# ==============================================================

summary_stats <- policy_long %>%
  group_by(Policy) %>%
  summarise(
    n = n(),
    Mean_Outcome = mean(Outcome),
    SD_Outcome = sd(Outcome),
    Mean_Regret = mean(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    SD_Regret = sd(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    MRO_Coverage = policy_coverage_df$Coverage[policy_coverage_df$Policy == unique(Policy)]
  ) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

knitr::kable(summary_stats, caption = "Consolidated Policy Performance Summary (Mean ¬± SD)")

# ==============================================================
# CCDN Simulation on Adult Dataset (UPDATED for Gemini LLM)
# ==============================================================

library(data.table)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(kableExtra)
library(tensorflow)
library(keras)
# --- New Libraries for Gemini API ---
library(gemini.R) 
library(jsonlite)
library(httr2)

set.seed(123)


# ==========================
# 1Ô∏è‚É£ Load Adult dataset
# ==========================
adult <- fread(
#  "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data",
  "adult.data.txt",
  header = FALSE,
  sep = ",",
  na.strings = "?",
  strip.white = TRUE
)

colnames(adult) <- c(
  "age", "workclass", "fnlwgt", "education", "education_num",
  "marital_status", "occupation", "relationship", "race", "sex",
  "capital_gain", "capital_loss", "hours_per_week", "native_country", "income"
)

# Trim whitespace, convert income to binary, drop NAs
adult <- adult %>%
  mutate(across(where(is.character), ~ trimws(.))) %>%
  mutate(income_binary = ifelse(income %in% c(">50K", ">50K."), 1L, 0L)) %>%
  na.omit()

# Keep a manageable sample (optional, but good for LLM testing)
if(nrow(adult) > 30000) adult <- adult %>% sample_n(30000)

# ==========================
# 2Ô∏è‚É£ Prepare features
# ==========================
numeric_covs <- c("age", "fnlwgt", "education_num", "capital_gain", "capital_loss", "hours_per_week")
other_covs <- setdiff(names(adult), c(numeric_covs, "income", "income_binary"))

# Encode categorical variables as numeric
adult_enc <- adult %>% mutate(across(all_of(other_covs), ~ as.numeric(factor(.))))

feature_cols <- c(numeric_covs, other_covs)
X_dt <- as.data.table(adult_enc[, ..feature_cols])

# Convert any non-numeric to numeric (safety)
for(j in seq_along(X_dt)) {
  if(!is.numeric(X_dt[[j]])) X_dt[[j]] <- as.numeric(factor(X_dt[[j]]))
}

# Standardize
X_mat <- scale(as.matrix(X_dt))
Y_full <- adult_enc$income_binary

# ==========================
# 3Ô∏è‚É£ Experimental design (2^4 factorial + blocking)
# ==========================
K <- 5
basic_design <- expand.grid(replicate(K, c(0,1), simplify=FALSE)) %>%
  dplyr::rename_with(~paste0("treatment", seq_along(.)))

n <- nrow(X_mat)

# Blocking using first two numeric covariates
k_blocks <- 10
block_input <- scale(as.matrix(X_dt[, numeric_covs[1:2], with = FALSE]))
km <- kmeans(block_input, centers = k_blocks, nstart = 20)
blocks <- km$cluster

# Assign treatments within blocks
assigned_treats <- matrix(NA, nrow = n, ncol = K)
colnames(assigned_treats) <- paste0("treatment", 1:K)
for(b in sort(unique(blocks))){
  ids_b <- which(blocks == b)
  m <- length(ids_b)
  rows <- sample(1:nrow(basic_design), size = m, replace = TRUE)
  assigned_treats[ids_b, ] <- as.matrix(basic_design[rows, , drop=FALSE])
}


# Use as.data.table and setDT to maintain internal references
adult_sim <- as.data.table(X_dt)
adult_sim[, id := seq_len(.N)]
adult_sim[, block := blocks]

# Use setbind or cbind on data.tables to avoid the shallow copy warning
adult_sim <- cbind(adult_sim, as.data.table(assigned_treats))
adult_sim[, outcome := Y_full] # Now this works without the warning

# ==========================
# 4Ô∏è‚É£ Balance diagnostics (unchanged)
# ==========================
adult_sim$comb <- apply(adult_sim[, paste0("treatment", 1:K), with = FALSE], 1, paste, collapse = "")
cat("Treatment combination frequencies:\n")
print(table(adult_sim$comb))

compute_smd <- function(df, group_var, covariates){
  smd_list <- lapply(covariates, function(var){
    vals <- df[[var]]
    group_means <- tapply(vals, df[[group_var]], mean, na.rm=TRUE)
    group_sds <- tapply(vals, df[[group_var]], sd, na.rm=TRUE)
    pooled_sd <- sqrt(mean(group_sds^2, na.rm=TRUE))
    smd_vals <- (group_means - mean(vals, na.rm=TRUE)) / pooled_sd
    data.frame(Variable=var, Group=names(group_means), Mean=as.numeric(group_means), SMD_vs_Global=as.numeric(smd_vals))
  })
  do.call(rbind, smd_list)
}

smd_summary <- compute_smd(adult_sim, "comb", numeric_covs)
ggplot(smd_summary, aes(x=Variable, y=SMD_vs_Global, color=Group)) +
  geom_point(size=2, alpha=0.7) +
  geom_hline(yintercept=c(-0.1,0.1), linetype="dashed", color="gray60") +
  theme_minimal(base_size=12) + coord_flip() +
  labs(title="Standardized Mean Differences by Treatment Combination",
       y="SMD vs Global Mean (|SMD| < 0.1 ‚âà balanced)", x="Feature")

# ==========================
# 5Ô∏è‚É£ Prepare data for CCDN (SUBSAMPLING ADJUSTED for LLM)
# ==========================
T_mat <- as.matrix(adult_sim[, paste0("treatment", 1:K), with = FALSE])
X <- X_mat
Y <- adult_sim$outcome

# Subsample 50 total observations for safe LLM API testing
set.seed(456)
idx <- sample(1:nrow(X), min(50, nrow(X)))
X <- X[idx,]; T_mat <- T_mat[idx,]; Y <- Y[idx]

set.seed(789)
train_idx <- sample(1:nrow(X), size = floor(0.8 * nrow(X)))
X_train <- X[train_idx,]; T_train <- T_mat[train_idx,]; Y_train <- Y[train_idx]
X_test  <- X[-train_idx,]; T_test  <- T_mat[-train_idx,]; Y_test  <- Y[-train_idx]
n_eval <- nrow(X_test)

# ==========================
# 6Ô∏è‚É£ CCDN model (Keras) (unchanged)
# ==========================
input_dim <- ncol(X_train) + K
hidden_units <- 64

inputs <- layer_input(shape = input_dim)
x <- inputs %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu") %>%
  layer_dense(units = hidden_units, activation = "relu")
outputs <- x %>% layer_dense(units = 1, activation = "sigmoid")
ccdn_model <- keras_model(inputs = inputs, outputs = outputs)

ccdn_model %>% compile(
  optimizer = optimizer_adam(0.001),
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

train_input <- as.matrix(cbind(X_train, T_train))
test_input  <- as.matrix(cbind(X_test, T_test))

history <- ccdn_model %>% fit(
  train_input, Y_train,
  validation_data = list(test_input, Y_test),
  epochs = 10, batch_size = 64, verbose = 0
)


# ==============================================================
# 7Ô∏è‚É£ Define Policies (Greedy, Thompson, Gemini LLM) (UPDATED)
# ==============================================================

all_combos <- as.matrix(expand.grid(replicate(K, c(0, 1), simplify = FALSE)))

# --- Greedy Policy (unchanged) ---
greedy_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    best_idx <- which.max(preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- Thompson Policy (unchanged) ---
thompson_policy <- function(X, model, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  for (i in 1:n) {
    input_mat <- cbind(matrix(rep(X[i, ], each = K_combos), ncol = ncol(X)), all_combos)
    mean_preds <- as.numeric(model %>% predict(input_mat, verbose=0))
    sampled_preds <- pmin(pmax(rnorm(length(mean_preds), mean = mean_preds, sd = 0.05), 0), 1)
    best_idx <- which.max(sampled_preds)
    selected[i, ] <- all_combos[best_idx, ]
  }
  selected
}

# --- üéØ Gemini LLM Policy (Actual API Call) ---

PROBABILITY_SCHEMA <- list(
  type = "OBJECT",
  properties = list(
    PredictedProbability = list(
      type = "NUMBER",
      description = "The predicted probability of the individual earning >50K, between 0 and 1, rounded to 4 decimal places."
    )
  ),
  required = c("PredictedProbability")
)

actual_llm_predict_reward <- function(context_features, treatment_vec, model_id = "gemini-2.5-flash") {
  
  if (nchar(Sys.getenv("GEMINI_API_KEY")) < 5) return(0.5)
  
  feature_labels <- c(numeric_covs, other_covs)
  X_str <- paste0(feature_labels, "=", round(context_features, 3), collapse=", ")
  T_str <- paste0("T", 1:length(treatment_vec), "=", treatment_vec, collapse=", ")
  
  prompt <- paste0(
    "Act as an expert socio-economic model. ",
    "Given the standardized features (age, education_num, occupation, race, sex, etc.) and a binary treatment vector, ",
    "predict the probability (a decimal between 0 and 1) that this individual earns more than $50K per year. ",
    "Features: ", X_str, ". ",
    "Treatments: ", T_str, "."
  )
  
  response <- tryCatch({
    gemini_structured(
      prompt = prompt,
      schema = PROBABILITY_SCHEMA,
      model_id = model_id,
      temperature = 0, 
      timeout = 30 
    )
  }, error = function(e) {
    warning(paste("Gemini API call failed:", e$message, "Returning 0.5."))
    return(NULL) 
  })
  
  if (!is.null(response) && !is.null(response$PredictedProbability)) {
    return(as.numeric(response$PredictedProbability))
  } else {
    return(0.5) 
  }
}

llm_policy <- function(X, all_combos) {
  n <- nrow(X)
  K_combos <- nrow(all_combos)
  selected <- matrix(NA, nrow = n, ncol = ncol(all_combos))
  
  print(paste("Executing Gemini LLM Policy on", n, "samples. Total API calls:", n * K_combos))
  
  for (i in 1:n) {
    combo_preds <- apply(all_combos, 1, function(t_vec)
      actual_llm_predict_reward(X[i, ], t_vec))
    
    best_idx <- which.max(combo_preds)
    selected[i, ] <- all_combos[best_idx, ]
    
    Sys.sleep(0.2) 
  }
  selected
}


# ==============================================================
# 8Ô∏è‚É£ Apply All Policies (No UCB, No Random)
# ==============================================================

X_eval <- X_test

policy_list <- list(
  Greedy    = greedy_policy(X_eval, ccdn_model, all_combos),
  Thompson  = thompson_policy(X_eval, ccdn_model, all_combos),
  LLM       = llm_policy(X_eval, all_combos)
)

# ==============================================================
# 9Ô∏è‚É£ Evaluate Policy Empirical Rewards
# ==============================================================
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr) # For statistical significance testing

# Helper function for vectorized CCDN predictions to improve speed
get_ccdn_preds <- function(features, actions) {
  # Batch input preparation
  inp <- as.matrix(cbind(features, actions))
  as.numeric(ccdn_model %>% predict(inp, verbose = 0))
}

# Reviewer 2: Ensure metrics use the test set size N
n_eval <- nrow(X_eval)

policy_preds <- lapply(policy_list, function(sel) {
  get_ccdn_preds(X_eval, sel)
})

policy_df <- as.data.frame(policy_preds)
colnames(policy_df) <- names(policy_list)

policy_long <- policy_df %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "PredictedOutcome")

# ==============================================================
# üîü Plot Policy Comparison (Reviewer 2: Statistical Assessment)
# ==============================================================

ggplot(policy_long, aes(x = Policy, y = PredictedOutcome, fill = Policy)) +
  geom_boxplot(alpha = 0.7, outlier.size = 0.5) +
  stat_compare_means(method = "wilcox.test", label = "p.signif", ref.group = "LLM") +
  theme_bw(base_size = 14) +
  labs(
    title = "Policy Predicted Outcomes (Adult Dataset)",
    subtitle = "Comparing policies against LLM baseline (Wilcoxon test)",
    y = "Predicted Probability of Income >50K",
    x = "Policy"
  )

# ==============================================================
# 11Ô∏è‚É£ MRO and Regret Evaluation (Reviewer 1: Fixed Terminology)
# ==============================================================

# Model-Relative Optimal (MRO): The best possible CCDN prediction per individual
mro_data <- apply(X_eval, 1, function(x_row) {
  # Batch predict all treatment combinations for a single covariate context
  context_rep <- matrix(rep(x_row, each = nrow(all_combos)), nrow = nrow(all_combos))
  preds <- get_ccdn_preds(context_rep, all_combos)
  
  return(c(val = max(preds), idx = which.max(preds)))
})

mro_vals <- mro_data["val", ]
mro_indices <- mro_data["idx", ]

# Regret: MRO value minus policy predictions
regret_list <- lapply(policy_preds, function(preds) mro_vals - preds)

regret_df <- as.data.frame(regret_list) %>%
  mutate(id = 1:n()) %>%
  pivot_longer(-id, names_to = "Policy", values_to = "Regret")

# Regret Plot (Reviewer 2: Improved Visual Standards)
ggplot(regret_df, aes(x = Policy, y = Regret, fill = Policy)) +
  geom_boxplot(alpha = 0.8) +
  theme_bw(base_size = 14) +
  labs(
    title = "Policy Regret Comparison (Adult Dataset)",
    subtitle = "Relative to Model-Relative Optimal (MRO)",
    y = "Regret (MRO Max - Policy Selection)",
    x = "Policy"
  )

# ==============================================================
# 12Ô∏è‚É£ MRO Coverage (Alignment with Optimal Actions)
# ==============================================================

policy_coverage <- sapply(names(policy_list), function(p_name) {
  sel_actions <- policy_list[[p_name]]
  matches <- sapply(1:n_eval, function(i) {
    # Check if the policy's chosen vector matches the MRO's vector
    identical(as.numeric(sel_actions[i, ]), as.numeric(all_combos[mro_indices[i], ]))
  })
  mean(matches)
})

policy_coverage_df <- data.frame(
  Policy = names(policy_coverage),
  Coverage = as.numeric(policy_coverage)
)

# Coverage Plot
ggplot(policy_coverage_df, aes(x = Policy, y = Coverage, fill = Policy)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = round(Coverage, 3)), vpos = -0.5) +
  ylim(0, 1.1) +
  theme_minimal(base_size = 14) +
  labs(
    title = "MRO Coverage (Fraction of Optimal Matches)",
    y = "Coverage Rate",
    x = "Policy"
  )

# ==============================================================
# CONSOLIDATED SUMMARY TABLE (Reviewer 2: Mean ¬± SD and N)
# ==============================================================

# Reviewer 2: Combining metrics into a single scientific table for clarity
summary_stats <- policy_long %>%
  group_by(Policy) %>%
  summarise(
    n = n(),
    Outcome_Mean = mean(PredictedOutcome),
    Outcome_SD = sd(PredictedOutcome),
    Regret_Mean = mean(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    Regret_SD = sd(regret_df$Regret[regret_df$Policy == unique(Policy)]),
    Coverage = policy_coverage_df$Coverage[policy_coverage_df$Policy == unique(Policy)]
  ) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

knitr::kable(
  summary_stats,
  caption = "Table 1: Adult Dataset Policy Performance Summary (Mean ¬± SD)"
)
