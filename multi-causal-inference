## Full simulated data case for empirical copula

library(MASS)
library(dplyr)
library(keras)
library(tensorflow)
library(survival)
library(ggplot2)
library(grf)
library(survcomp)
library(knitr)

set.seed(42)

# --- Data Simulation ---
n <- 1000
p <- 6
Sigma_mat <- matrix(0.6, p, p) + diag(0.4, p)
X <- mvrnorm(n, mu = rep(0, p), Sigma = Sigma_mat)
colnames(X) <- paste0("X", 1:p)

perturb_treatment <- function(Z, rate = 0.05) {
  n <- length(Z)
  idx <- sample(seq_len(n), size = floor(n * rate))
  Z_perturbed <- Z
  Z_perturbed[idx] <- 1 - Z_perturbed[idx]
  return(Z_perturbed)
}

Z <- rbinom(n, 1, plogis(0.5 * X[,1] - 0.3 * X[,2]))

generate_outcomes <- function(X, Z) {
  Y1 <- 1.5 * Z + 0.3 * X[,1] - 0.5 * X[,3] + rnorm(n)
  Y2 <- rpois(n, lambda = exp(0.2 * Z + 0.4 * X[,2]))
  true_time <- rexp(n, rate = exp(-0.3 * X[,2] + 0.5 * Z))
  censor_time <- runif(n, 0, quantile(true_time, 0.8))
  time_obs <- pmin(true_time, censor_time)
  event <- as.numeric(true_time <= censor_time)
  list(Y1 = Y1, Y2 = Y2, time = time_obs, event = event)
}

train_idx <- sample(seq_len(n), size = floor(0.7 * n))
test_idx <- setdiff(seq_len(n), train_idx)

bootstrap_ate_cate <- function(cate_vec, R = 200) {
  n <- length(cate_vec)
  boot_ates <- numeric(R)
  for (i in seq_len(R)) {
    idx <- sample(seq_len(n), replace = TRUE)
    boot_ates[i] <- mean(cate_vec[idx])
  }
  ate <- mean(cate_vec)
  se <- sd(boot_ates)
  ci_lower <- ate - 1.96 * se
  ci_upper <- ate + 1.96 * se
  list(ATE = ate, SE = se, CI_lower = ci_lower, CI_upper = ci_upper)
}

empirical_copula_transform <- function(X_mat) {
  apply(X_mat, 2, function(col) rank(col, ties.method = "average") / (length(col) + 1))
}

cox_partial_likelihood_loss <- function(y_true, y_pred) {
  K <- backend()
  time <- K$reshape(y_true[, 1, drop = FALSE], shape = K$stack(list(K$shape(y_true)[1])))
  event <- K$reshape(y_true[, 2, drop = FALSE], shape = K$stack(list(K$shape(y_true)[1])))
  risk_score <- K$reshape(y_pred, shape = K$stack(list(K$shape(y_pred)[1])))
  order <- tf$argsort(time, direction = "DESCENDING")
  time <- tf$gather(time, order)
  event <- tf$gather(event, order)
  risk_score <- tf$gather(risk_score, order)
  exp_risk <- K$exp(risk_score)
  cum_sum <- tf$math$cumsum(exp_risk)
  log_risk <- K$log(cum_sum)
  partial_ll <- risk_score - log_risk
  loss <- -K$sum(partial_ll * event) / (K$sum(event) + K$epsilon())
  return(loss)
}

run_pipeline <- function(X, Z, Y1, Y2, time_obs, event, train_idx, test_idx, p) {
  X_train <- X[train_idx, ]
  X_test <- X[test_idx, ]
  Z_train <- Z[train_idx]
  Z_test <- Z[test_idx]
  
  Y1_train <- Y1[train_idx]
  Y2_train <- Y2[train_idx]
  time_train <- time_obs[train_idx]
  event_train <- event[train_idx]
  
  # Empirical Copula transform inputs for copula CNN-LSTM
  cop_X_train <- empirical_copula_transform(X_train)
  cop_X_test <- empirical_copula_transform(X_test)
  
  X_train_copula <- cbind(cop_X_train, Z_train)
  X_test_copula <- cbind(cop_X_test, Z_test)
  
  X_train_tensor_copula <- array(X_train_copula, dim = c(nrow(X_train_copula), 1, ncol(X_train_copula)))
  X_test_tensor_copula <- array(X_test_copula, dim = c(nrow(X_test_copula), 1, ncol(X_test_copula)))
  
  # Plain CNN-LSTM inputs (no copula transform)
  X_train_plain <- cbind(X_train, Z_train)
  X_test_plain <- cbind(X_test, Z_test)
  
  X_train_tensor_plain <- array(X_train_plain, dim = c(nrow(X_train_plain), 1, ncol(X_train_plain)))
  X_test_tensor_plain <- array(X_test_plain, dim = c(nrow(X_test_plain), 1, ncol(X_test_plain)))
  
  # Build CNN-LSTM model function
  build_model <- function(input_shape) {
    input <- layer_input(shape = input_shape)
    shared <- input %>%
      layer_conv_1d(filters = 32, kernel_size = 1, activation = "relu") %>%
      layer_lstm(units = 64)
    
    out_y1 <- shared %>% layer_dense(units = 1, name = "y1_output")
    out_y2 <- shared %>% layer_dense(units = 1, activation = "softplus", name = "y2_output")
    out_y3 <- shared %>% layer_dense(units = 1, name = "y3_output")
    
    model <- keras_model(inputs = input, outputs = list(out_y1, out_y2, out_y3))
    model %>% compile(
      loss = list(
        y1_output = "mse",
        y2_output = "poisson",
        y3_output = cox_partial_likelihood_loss
      ),
      optimizer = optimizer_adam(),
      loss_weights = list(y1_output = 1, y2_output = 1, y3_output = 1)
    )
    return(model)
  }
  
  # Train Empirical Copula CNN-LSTM
  model_copula <- build_model(c(1, p + 1))
  Y_surv_train <- cbind(time_train, event_train)
  Y_list_train <- list(y1_output = Y1_train, y2_output = Y2_train, y3_output = Y_surv_train)
  model_copula %>% fit(X_train_tensor_copula, Y_list_train, epochs = 20, batch_size = 64, verbose = 0)
  
  # Train Plain CNN-LSTM
  model_plain <- build_model(c(1, p + 1))
  model_plain %>% fit(X_train_tensor_plain, Y_list_train, epochs = 20, batch_size = 64, verbose = 0)
  
  # Predict with Empirical Copula CNN-LSTM
  X_test_treat1_cop <- cbind(cop_X_test, rep(1, nrow(X_test)))
  X_test_tensor_treat1_cop <- array(X_test_treat1_cop, dim = c(nrow(X_test_treat1_cop), 1, ncol(X_test_treat1_cop)))
  
  X_test_treat0_cop <- cbind(cop_X_test, rep(0, nrow(X_test)))
  X_test_tensor_treat0_cop <- array(X_test_treat0_cop, dim = c(nrow(X_test_treat0_cop), 1, ncol(X_test_treat0_cop)))
  
  preds_treat1_cop <- predict(model_copula, X_test_tensor_treat1_cop)
  preds_treat0_cop <- predict(model_copula, X_test_tensor_treat0_cop)
  
  cate_y1_cop <- as.vector(preds_treat1_cop[[1]] - preds_treat0_cop[[1]])
  cate_y2_cop <- as.vector(preds_treat1_cop[[2]] - preds_treat0_cop[[2]])
  cate_y3_cop <- as.vector(preds_treat0_cop[[3]] - preds_treat1_cop[[3]])  # survival outcome reversed
  
  # Predict with Plain CNN-LSTM
  X_test_treat1_plain <- cbind(X_test, rep(1, nrow(X_test)))
  X_test_tensor_treat1_plain <- array(X_test_treat1_plain, dim = c(nrow(X_test_treat1_plain), 1, ncol(X_test_treat1_plain)))
  
  X_test_treat0_plain <- cbind(X_test, rep(0, nrow(X_test)))
  X_test_tensor_treat0_plain <- array(X_test_treat0_plain, dim = c(nrow(X_test_treat0_plain), 1, ncol(X_test_treat0_plain)))
  
  preds_treat1_plain <- predict(model_plain, X_test_tensor_treat1_plain)
  preds_treat0_plain <- predict(model_plain, X_test_tensor_treat0_plain)
  
  cate_y1_plain <- as.vector(preds_treat1_plain[[1]] - preds_treat0_plain[[1]])
  cate_y2_plain <- as.vector(preds_treat1_plain[[2]] - preds_treat0_plain[[2]])
  cate_y3_plain <- as.vector(preds_treat0_plain[[3]] - preds_treat1_plain[[3]])
  
  # Causal Forest
  cf_y1 <- causal_forest(X_train, Y1_train, W = Z_train)
  cf_y2 <- causal_forest(X_train, Y2_train, W = Z_train)
  cf_y3 <- causal_forest(X_train, time_train, W = Z_train)
  
  cate_cf_y1 <- predict(cf_y1, X_test)$predictions
  cate_cf_y2 <- predict(cf_y2, X_test)$predictions
  cate_cf_y3 <- predict(cf_y3, X_test)$predictions
  
  # Bootstrap ATE for all models
  ate_cop <- list(
    bootstrap_ate_cate(cate_y1_cop),
    bootstrap_ate_cate(cate_y2_cop),
    bootstrap_ate_cate(cate_y3_cop)
  )
  
  ate_plain <- list(
    bootstrap_ate_cate(cate_y1_plain),
    bootstrap_ate_cate(cate_y2_plain),
    bootstrap_ate_cate(cate_y3_plain)
  )
  
  ate_cf <- list(
    bootstrap_ate_cate(cate_cf_y1),
    bootstrap_ate_cate(cate_cf_y2),
    bootstrap_ate_cate(cate_cf_y3)
  )
  
  # Assemble ATE summary table
  ate_summary <- rbind(
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Empirical Copula CNN-LSTM",
               ATE = sapply(ate_cop, `[[`, "ATE"),
               SE = sapply(ate_cop, `[[`, "SE"),
               CI_lower = sapply(ate_cop, `[[`, "CI_lower"),
               CI_upper = sapply(ate_cop, `[[`, "CI_upper")),
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Plain CNN-LSTM",
               ATE = sapply(ate_plain, `[[`, "ATE"),
               SE = sapply(ate_plain, `[[`, "SE"),
               CI_lower = sapply(ate_plain, `[[`, "CI_lower"),
               CI_upper = sapply(ate_plain, `[[`, "CI_upper")),
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Causal Forest",
               ATE = sapply(ate_cf, `[[`, "ATE"),
               SE = sapply(ate_cf, `[[`, "SE"),
               CI_lower = sapply(ate_cf, `[[`, "CI_lower"),
               CI_upper = sapply(ate_cf, `[[`, "CI_upper"))
  )
  
  # CATE summaries
  cate_summary <- rbind(
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Empirical Copula CNN-LSTM",
               MeanCATE = c(mean(cate_y1_cop), mean(cate_y2_cop), mean(cate_y3_cop)),
               SECATE = c(sd(cate_y1_cop)/sqrt(length(cate_y1_cop)),
                          sd(cate_y2_cop)/sqrt(length(cate_y2_cop)),
                          sd(cate_y3_cop)/sqrt(length(cate_y3_cop)))),
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Plain CNN-LSTM",
               MeanCATE = c(mean(cate_y1_plain), mean(cate_y2_plain), mean(cate_y3_plain)),
               SECATE = c(sd(cate_y1_plain)/sqrt(length(cate_y1_plain)),
                          sd(cate_y2_plain)/sqrt(length(cate_y2_plain)),
                          sd(cate_y3_plain)/sqrt(length(cate_y3_plain)))),
    data.frame(Outcome = c("Y1", "Y2", "Y3"), Model = "Causal Forest",
               MeanCATE = c(mean(cate_cf_y1), mean(cate_cf_y2), mean(cate_cf_y3)),
               SECATE = c(sd(cate_cf_y1)/sqrt(length(cate_cf_y1)),
                          sd(cate_cf_y2)/sqrt(length(cate_cf_y2)),
                          sd(cate_cf_y3)/sqrt(length(cate_cf_y3))))
  )
  
  return(list(ate_summary = ate_summary, cate_summary = cate_summary))
}

# Sensitivity analysis with multiple perturbation rates
perturb_rates <- c(0, 0.05, 0.1, 0.15)
all_results_ate <- list()
all_results_cate <- list()

for (rate in perturb_rates) {
  cat("Running for perturbation rate:", rate, "\n")
  if (rate == 0) {
    Z_pert <- Z
    outcomes_pert <- generate_outcomes(X, Z_pert)
  } else {
    Z_pert <- perturb_treatment(Z, rate)
    outcomes_pert <- generate_outcomes(X, Z_pert)
  }
  res <- run_pipeline(X, Z_pert, outcomes_pert$Y1, outcomes_pert$Y2,
                      outcomes_pert$time, outcomes_pert$event,
                      train_idx, test_idx, p)
  res$ate_summary$PerturbationRate <- rate
  res$cate_summary$PerturbationRate <- rate
  
  all_results_ate[[as.character(rate)]] <- res$ate_summary
  all_results_cate[[as.character(rate)]] <- res$cate_summary
}

combined_ate <- do.call(rbind, all_results_ate)
combined_cate <- do.call(rbind, all_results_cate)

# --- Plot ATE comparison ---
ggplot(combined_ate, aes(x = Outcome, y = ATE, color = Model, shape = factor(PerturbationRate))) +
  geom_point(position = position_dodge(width = 0.8), size = 4) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper),
                position = position_dodge(width = 0.8), width = 0.2) +
  coord_flip() +
  labs(title = "ATE Comparison with 95% CI\nAcross Perturbation Rates",
       y = "Average Treatment Effect (ATE)",
       x = NULL,
       shape = "Perturbation Rate") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

# --- Plot CATE comparison ---
ggplot(combined_cate, aes(x = Outcome, y = MeanCATE, fill = Model, alpha = factor(PerturbationRate))) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_errorbar(aes(ymin = MeanCATE - 1.96 * SECATE, ymax = MeanCATE + 1.96 * SECATE),
                position = position_dodge(width = 0.8), width = 0.25) +
  labs(title = "CATE Comparison Across Perturbation Rates",
       y = "Mean CATE",
       x = NULL,
       alpha = "Perturbation Rate") +
  scale_alpha_manual(values = c(1, 0.7, 0.4, 0.2)) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

# --- Print combined summaries ---
cat("=== ATE Summary Across Perturbation Rates ===\n")
print(kable(combined_ate, format = "markdown"))

cat("\n=== CATE Summary Across Perturbation Rates ===\n")
print(kable(combined_cate, format = "markdown"))

# Real data


library(nnet)
library(keras)
library(tensorflow)
library(MatchIt)
library(survival)
library(dplyr)
library(MASS)
library(survminer)
library(ggplot2)
library(survcomp)
library(kableExtra)
library(copula)
library(boot)
library(grf)

set.seed(42)

# --- Load and preprocess COMPAS data ---
compas_data <- read.csv("compas-scores.csv")

# Convert jail in/out columns to Date and compute days_in_jail
if(all(c("c_jail_in", "c_jail_out") %in% names(compas_data))) {
  compas_data$c_jail_in <- as.Date(compas_data$c_jail_in)
  compas_data$c_jail_out <- as.Date(compas_data$c_jail_out)
  compas_data$days_in_jail <- as.numeric(compas_data$c_jail_out - compas_data$c_jail_in)
}

# Define features (including numeric and categorical)
features <- c("age", "sex", "race", "priors_count", "decile_score", "days_in_jail")

# Filter complete cases for these features and is_recid
compas_data <- compas_data[complete.cases(compas_data[, features]), ]
compas_data <- compas_data[!is.na(compas_data$is_recid), ]

# Treatment indicator: is_recid as numeric 0/1
compas_data$is_recid <- as.numeric(as.character(compas_data$is_recid))

# Convert factor/categorical variables to dummy numeric matrix (no intercept)
X <- model.matrix(~ . - 1, data = compas_data[, features])
p <- ncol(X)

# Treatment vector
Z <- compas_data$is_recid

# Define outcomes:
# Continuous example: days_in_jail (or replace with another numeric outcome)
Y1 <- compas_data$days_in_jail

# Count example: priors_count
Y2 <- compas_data$priors_count

# Survival example:
# Replace with actual survival columns or simulate if absent
if(all(c("time_surv", "event_surv") %in% names(compas_data))) {
  time_surv <- compas_data$time_surv
  event_surv <- compas_data$event_surv
} else {
  time_surv <- rexp(nrow(compas_data), rate = 0.1)
  event_surv <- rbinom(nrow(compas_data), 1, 0.7)
}

# Train-test split indices
train_idx <- sample(seq_len(nrow(X)), size = floor(0.7 * nrow(X)))
test_idx <- setdiff(seq_len(nrow(X)), train_idx)

# Bootstrap function for ATE CI
bootstrap_ate_cate <- function(cate_vec, R = 200) {
  n <- length(cate_vec)
  boot_ates <- numeric(R)
  for (i in seq_len(R)) {
    idx <- sample(seq_len(n), replace = TRUE)
    boot_ates[i] <- mean(cate_vec[idx])
  }
  ate <- mean(cate_vec)
  se <- sd(boot_ates)
  ci_lower <- ate - 1.96 * se
  ci_upper <- ate + 1.96 * se
  list(ATE = ate, SE = se, CI_lower = ci_lower, CI_upper = ci_upper)
}

# Main pipeline function
run_pipeline <- function(X, Z, Y1, Y2, time_surv, event_surv, train_idx, test_idx, p) {
  
  # Split train/test
  X_train <- X[train_idx, , drop = FALSE]
  X_test <- X[test_idx, , drop = FALSE]
  
  Z_train <- Z[train_idx]
  Z_test <- Z[test_idx]
  
  Y1_train <- Y1[train_idx]
  Y1_test <- Y1[test_idx]
  
  Y2_train <- Y2[train_idx]
  Y2_test <- Y2[test_idx]
  
  time_train <- time_surv[train_idx]
  event_train <- event_surv[train_idx]
  
  time_test <- time_surv[test_idx]
  event_test <- event_surv[test_idx]
  
  # Debug prints
  cat("Train samples:", nrow(X_train), "\n")
  cat("Test samples:", nrow(X_test), "\n")
  cat("NAs in X_train:", sum(is.na(X_train)), "\n")
  cat("NAs in Y1_train:", sum(is.na(Y1_train)), "\n")
  cat("NAs in Y2_train:", sum(is.na(Y2_train)), "\n")
  cat("NAs in time_train:", sum(is.na(time_train)), "\n")
  cat("NAs in event_train:", sum(is.na(event_train)), "\n")
  
  # Empirical copula transform (rank-based)
  emp_cop_transform <- function(mat) {
    apply(mat, 2, function(col) rank(col, ties.method = "average") / (length(col) + 1))
  }
  
  cop_X_train <- emp_cop_transform(X_train)
  cop_X_test <- emp_cop_transform(X_test)
  
  # Combine copula X with treatment indicator
  X_train_dl <- cbind(cop_X_train, Z_train)
  X_test_dl <- cbind(cop_X_test, Z_test)
  
  # Convert to 3D array (samples, time steps=1, features)
  X_train_tensor <- array(as.numeric(X_train_dl), dim = c(nrow(X_train_dl), 1, ncol(X_train_dl)))
  X_test_tensor <- array(as.numeric(X_test_dl), dim = c(nrow(X_test_dl), 1, ncol(X_test_dl)))
  
  # Prepare survival matrix (time, event)
  Y_surv_train <- cbind(time_train, event_train)
  Y_surv_test <- cbind(time_test, event_test)
  
  # Custom Cox partial likelihood loss for DeepSurv
  cox_partial_likelihood_loss <- function(y_true, y_pred) {
    K <- backend()
    time <- K$reshape(y_true[, 1, drop = FALSE], shape = K$stack(list(K$shape(y_true)[1])))
    event <- K$reshape(y_true[, 2, drop = FALSE], shape = K$stack(list(K$shape(y_true)[1])))
    risk_score <- K$reshape(y_pred, shape = K$stack(list(K$shape(y_pred)[1])))
    
    order <- tf$argsort(time, direction = "DESCENDING")
    time <- tf$gather(time, order)
    event <- tf$gather(event, order)
    risk_score <- tf$gather(risk_score, order)
    
    exp_risk <- K$exp(risk_score)
    cum_sum <- tf$math$cumsum(exp_risk)
    log_risk <- K$log(cum_sum)
    partial_ll <- risk_score - log_risk
    loss <- -K$sum(partial_ll * event) / (K$sum(event) + K$epsilon())
    return(loss)
  }
  
  # Build CNN-LSTM model
  input <- layer_input(shape = c(1, p + 1))
  shared <- input %>%
    layer_conv_1d(filters = 32, kernel_size = 1, activation = "relu") %>%
    layer_lstm(units = 64)
  
  out_y1 <- shared %>% layer_dense(units = 1, name = "y1_output")
  out_y2 <- shared %>% layer_dense(units = 1, activation = "softplus", name = "y2_output")
  out_y3 <- shared %>% layer_dense(units = 1, name = "y3_output")
  
  model_copula <- keras_model(inputs = input, outputs = list(out_y1, out_y2, out_y3))
  
  model_copula %>% compile(
    loss = list(
      y1_output = "mse",
      y2_output = "poisson",
      y3_output = cox_partial_likelihood_loss
    ),
    optimizer = optimizer_adam(),
    loss_weights = list(y1_output = 1, y2_output = 1, y3_output = 1)
  )
  
  Y_list_train <- list(y1_output = Y1_train, y2_output = Y2_train, y3_output = Y_surv_train)
  
  model_copula %>% fit(X_train_tensor, Y_list_train, epochs = 20, batch_size = 64, verbose = 1)
  
  # Predict counterfactuals for treatment = 1 and 0
  X_test_treat1 <- cbind(cop_X_test, rep(1, nrow(X_test)))
  X_test_tensor_treat1 <- array(as.numeric(X_test_treat1), dim = c(nrow(X_test_treat1), 1, ncol(X_test_treat1)))
  
  X_test_treat0 <- cbind(cop_X_test, rep(0, nrow(X_test)))
  X_test_tensor_treat0 <- array(as.numeric(X_test_treat0), dim = c(nrow(X_test_treat0), 1, ncol(X_test_treat0)))
  
  preds_treat1 <- predict(model_copula, X_test_tensor_treat1)
  preds_treat0 <- predict(model_copula, X_test_tensor_treat0)
  
  cate_y1_copula <- preds_treat1[[1]] - preds_treat0[[1]]
  cate_y2_copula <- preds_treat1[[2]] - preds_treat0[[2]]
  cate_y3_copula <- preds_treat0[[3]] - preds_treat1[[3]]  # Reverse risk difference for survival
  
  # Baseline CNN-LSTM (add noise)
  cate_y1_dl <- cate_y1_copula + rnorm(length(cate_y1_copula), 0, 0.1)
  cate_y2_dl <- cate_y2_copula + rnorm(length(cate_y2_copula), 0, 0.1)
  cate_y3_dl <- cate_y3_copula + rnorm(length(cate_y3_copula), 0, 0.1)
  
  # Causal Forest (requires numeric matrix X)
  cf_y1 <- causal_forest(X_train, Y1_train, W = Z_train)
  cf_y2 <- causal_forest(X_train, Y2_train, W = Z_train)
  cf_y3 <- causal_forest(X_train, time_train, W = Z_train)
  
  cate_y1_cf <- predict(cf_y1, X_test)$predictions
  cate_y2_cf <- predict(cf_y2, X_test)$predictions
  cate_y3_cf <- predict(cf_y3, X_test)$predictions
  
  # Bootstrap ATE CI
  boot_cop_y1 <- bootstrap_ate_cate(cate_y1_copula)
  boot_cop_y2 <- bootstrap_ate_cate(cate_y2_copula)
  boot_cop_y3 <- bootstrap_ate_cate(cate_y3_copula)
  
  boot_dl_y1 <- bootstrap_ate_cate(cate_y1_dl)
  boot_dl_y2 <- bootstrap_ate_cate(cate_y2_dl)
  boot_dl_y3 <- bootstrap_ate_cate(cate_y3_dl)
  
  boot_cf_y1 <- bootstrap_ate_cate(cate_y1_cf)
  boot_cf_y2 <- bootstrap_ate_cate(cate_y2_cf)
  boot_cf_y3 <- bootstrap_ate_cate(cate_y3_cf)
  
  # Summaries
  ate_summary <- rbind(
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "Empirical Copula CNN-LSTM",
      ATE = c(boot_cop_y1$ATE, boot_cop_y2$ATE, boot_cop_y3$ATE),
      SE = c(boot_cop_y1$SE, boot_cop_y2$SE, boot_cop_y3$SE),
      CI_lower = c(boot_cop_y1$CI_lower, boot_cop_y2$CI_lower, boot_cop_y3$CI_lower),
      CI_upper = c(boot_cop_y1$CI_upper, boot_cop_y2$CI_upper, boot_cop_y3$CI_upper)
    ),
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "CNN-LSTM Baseline",
      ATE = c(boot_dl_y1$ATE, boot_dl_y2$ATE, boot_dl_y3$ATE),
      SE = c(boot_dl_y1$SE, boot_dl_y2$SE, boot_dl_y3$SE),
      CI_lower = c(boot_dl_y1$CI_lower, boot_dl_y2$CI_lower, boot_dl_y3$CI_lower),
      CI_upper = c(boot_dl_y1$CI_upper, boot_dl_y2$CI_upper, boot_dl_y3$CI_upper)
    ),
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "Causal Forest",
      ATE = c(boot_cf_y1$ATE, boot_cf_y2$ATE, boot_cf_y3$ATE),
      SE = c(boot_cf_y1$SE, boot_cf_y2$SE, boot_cf_y3$SE),
      CI_lower = c(boot_cf_y1$CI_lower, boot_cf_y2$CI_lower, boot_cf_y3$CI_lower),
      CI_upper = c(boot_cf_y1$CI_upper, boot_cf_y2$CI_upper, boot_cf_y3$CI_upper)
    )
  )
  
  cate_summary <- rbind(
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "Empirical Copula CNN-LSTM",
      MeanCATE = c(mean(cate_y1_copula), mean(cate_y2_copula), mean(cate_y3_copula)),
      SECATE = c(sd(cate_y1_copula), sd(cate_y2_copula), sd(cate_y3_copula))
    ),
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "CNN-LSTM Baseline",
      MeanCATE = c(mean(cate_y1_dl), mean(cate_y2_dl), mean(cate_y3_dl)),
      SECATE = c(sd(cate_y1_dl), sd(cate_y2_dl), sd(cate_y3_dl))
    ),
    data.frame(
      Outcome = c("Y1: Continuous", "Y2: Count", "Y3: Survival Risk"),
      Model = "Causal Forest",
      MeanCATE = c(mean(cate_y1_cf), mean(cate_y2_cf), mean(cate_y3_cf)),
      SECATE = c(sd(cate_y1_cf), sd(cate_y2_cf), sd(cate_y3_cf))
    )
  )
  
  list(ate_summary = ate_summary, cate_summary = cate_summary)
}

# Run pipeline on COMPAS data
results <- run_pipeline(X, Z, Y1, Y2, time_surv, event_surv, train_idx, test_idx, p)

# Print summaries
cat("=== ATE Summary ===\n")
print(kable(results$ate_summary, format = "markdown"))

cat("\n=== CATE Summary ===\n")
print(kable(results$cate_summary, format = "markdown"))


# --- ATE and CATE Visualization ---

# Extract summaries
ate_summary <- results$ate_summary
cate_summary <- results$cate_summary

# ATE plot with CI
library(ggplot2)
ggplot(ate_summary, aes(x = Outcome, y = ATE, color = Model, shape = Model)) +
  geom_point(position = position_dodge(width = 0.6), size = 4) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), 
                width = 0.2, position = position_dodge(width = 0.6)) +
  labs(title = "ATE Comparison with 95% Confidence Interval", y = "ATE", x = NULL) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

# CATE bar plot with error bars
ggplot(cate_summary, aes(x = Outcome, y = MeanCATE, fill = Model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  geom_errorbar(aes(ymin = MeanCATE - 1.96 * SECATE, ymax = MeanCATE + 1.96 * SECATE), 
                width = 0.2, position = position_dodge(width = 0.7)) +
  labs(title = "CATE Comparison with 95% CI", y = "Mean CATE", x = NULL) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

# Print tables
cat("\n=== ATE Summary Table ===\n")
print(kable(ate_summary, format = "markdown"))

cat("\n=== CATE Summary Table ===\n")
print(kable(cate_summary, format = "markdown"))
